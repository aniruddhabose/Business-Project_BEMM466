{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c013914-57d5-4f00-bf1a-10b3db6b7e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Processed: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Project paths\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED = PROJ_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Ensure write dirs exist\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "print(\"Processed:\", DATA_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdb728-e294-401b-8519-9eab58fc40d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7f2ba7-cd1f-44c2-b4f5-2cb659898a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_raw(filename: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a CSV from data/raw by filename only (no absolute paths).\n",
    "    Example: df = load_csv_raw(\"series-280625.csv\")\n",
    "    \"\"\"\n",
    "    path = DATA_RAW / filename\n",
    "    # Try utf-8 then latin-1 fallback\n",
    "    try:\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"latin-1\", **kwargs)\n",
    "\n",
    "def load_excel_raw(filename: str, sheet_name=0, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read an Excel sheet from data/raw.\n",
    "    Example: df = load_excel_raw(\"ukpopulationestimates183820231.xlsx\", sheet_name=\"MYE\")\n",
    "    \"\"\"\n",
    "    path = DATA_RAW / filename\n",
    "    return pd.read_excel(path, sheet_name=sheet_name, **kwargs)\n",
    "\n",
    "def save_interim(df: pd.DataFrame, filename: str) -> Path:\n",
    "    \"\"\"\n",
    "    Save a tidy CSV to data/interim.\n",
    "    Example: save_interim(tidy_df, \"gdp_q_tidy.csv\")\n",
    "    \"\"\"\n",
    "    out = DATA_INTERIM / filename\n",
    "    df.to_csv(out, index=False)\n",
    "    return out\n",
    "\n",
    "def save_processed(df: pd.DataFrame, filename: str) -> Path:\n",
    "    \"\"\"\n",
    "    Save a processed/combined CSV to data/processed.\n",
    "    Example: save_processed(master_df, \"master_panel.csv\")\n",
    "    \"\"\"\n",
    "    out = DATA_PROCESSED / filename\n",
    "    df.to_csv(out, index=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b6732-bc7e-4603-9352-7fcbe06cb442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa53ca42-72d4-4583-93f2-8af87345a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format\")\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^\\w_]+\", \"\", regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def parse_year_quarter_to_period(year, quarter) -> pd.Series:\n",
    "    y = pd.to_numeric(year, errors=\"coerce\")\n",
    "    q = pd.to_numeric(quarter, errors=\"coerce\")\n",
    "    ok = y.notna() & q.notna() & q.between(1,4)\n",
    "    per = pd.Series(pd.NaT, index=pd.Index(range(len(y))), dtype=\"datetime64[ns]\")\n",
    "    if ok.any():\n",
    "        idx = ok[ok].index\n",
    "        per.loc[idx] = pd.PeriodIndex(\n",
    "            (y.loc[idx].astype(int).astype(str) + \"Q\" + q.loc[idx].astype(int).astype(str)).values,\n",
    "            freq=\"Q\"\n",
    "        ).to_timestamp(how=\"end\")\n",
    "    return per\n",
    "\n",
    "def parse_generic_yq_strings(s: pd.Series) -> pd.Series:\n",
    "    txt = s.astype(str).str.strip()\n",
    "    txt = (\n",
    "        txt.str.replace(r\"quarter\\s*\", \"Q\", flags=re.I, regex=True)\n",
    "           .str.replace(r\"\\s+\", \"\", regex=True)\n",
    "           .str.replace(r\"^Q([1-4])(\\d{4})$\", r\"\\2Q\\1\", regex=True)\n",
    "    )\n",
    "    mask = txt.str.match(r\"^\\d{4}Q[1-4]$\", na=False)\n",
    "    out = pd.Series(pd.NaT, index=s.index, dtype=\"datetime64[ns]\")\n",
    "    if mask.any():\n",
    "        out.loc[mask] = pd.PeriodIndex(txt[mask], freq=\"Q\").to_timestamp(how=\"end\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da632f3-6d16-44ac-a918-2d705d9ec565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a267ddbf-0ffd-477a-9603-3c75886905b2",
   "metadata": {},
   "source": [
    "## 1) Annual Defence Expenditure – Combined.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b15957-008e-4a9f-b9fa-318cfd0b6634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Processed: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\processed\n",
      "Using defence workbook: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\Annual Defence Expenditure - Combined.xlsx\n",
      "Saved tidy annual to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\defence_fy_tidy.csv\n",
      "Saved quarterly nominal (long) to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\defence_q_nominal_long.csv\n",
      "Saved quarterly nominal (wide) to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\defence_q_nominal_wide.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aniruddha\\AppData\\Local\\Temp\\ipykernel_25204\\111195262.py:231: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  q_wide = (q_nom\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# (Optional) 'display' safety for non-notebook contexts\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    def display(x): print(x)\n",
    "\n",
    "# ----------------------------\n",
    "# Project paths (centralized)\n",
    "# ----------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()           # run notebook from project root\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED = PROJ_ROOT / \"data\" / \"processed\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "print(\"Processed:\", DATA_PROCESSED)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) LOAD & CLEAN (your logic, refined)\n",
    "# ----------------------------\n",
    "def load_defence(filepath):\n",
    "    raw = pd.read_excel(filepath, sheet_name='Annual Defence Spending', header=None)\n",
    "\n",
    "    # Find header row with FY labels like \"2004-05\"\n",
    "    header_row = raw.index[\n",
    "        raw.apply(lambda r: r.astype(str).str.contains(r'\\d{4}-\\d{2}').any(), axis=1)\n",
    "    ][0]\n",
    "    cols = raw.loc[header_row].tolist()\n",
    "\n",
    "    # Data starts two rows below the header; restrict to header width\n",
    "    df = raw.iloc[header_row + 2:, :len(cols)].copy()\n",
    "    df.columns = ['line'] + cols[1:len(df.columns)]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # --- Normalize line labels (strip numbering, tidy variants) ---\n",
    "    def base_label(s: str):\n",
    "        s = str(s).replace('\\u00a0', ' ')\n",
    "        s = re.sub(r'^\\s*', '', s)\n",
    "        s = re.sub(r'^\\d+(?:\\.\\d+)?(?:[.)])?\\s*', '', s)   # \"2\", \"2.\", \"2.1\", \"2)\" etc.\n",
    "        s = re.sub(r'\\s*\\(\\d+\\)\\s*$', '', s)               # trailing note numbers \"(4)\"\n",
    "        s = re.sub(r'\\s+', ' ', s).strip().lower()\n",
    "        s = (s.replace('r & d', 'r&d')\n",
    "               .replace('r. & d.', 'r&d')\n",
    "               .replace('r & d.', 'r&d')\n",
    "               .replace('n. e. c.', 'n.e.c.')\n",
    "               .replace('n . e . c .', 'n.e.c.'))\n",
    "        return s\n",
    "\n",
    "    df['base'] = df['line'].apply(base_label)\n",
    "\n",
    "    # Locate where the economic block (Current/Capital) starts\n",
    "    econ_start = df.index[df['base'].isin({'current expenditure', 'capital expenditure'})]\n",
    "    split_pos = int(econ_start.min()) if len(econ_start) else None\n",
    "\n",
    "    # Map to final labels; split \"total defence\" into 1 (functional) and 2 (economic)\n",
    "    def to_final_label(b, pos):\n",
    "        if b == 'military defence': return 'Military defence'\n",
    "        if b == 'civil defence': return 'Civil defence'\n",
    "        if b == 'foreign military aid': return 'Foreign military aid'\n",
    "        if b == 'r&d defence': return 'R&D defence'\n",
    "        if b == 'defence n.e.c.': return 'Defence n.e.c.'\n",
    "        if b == 'current expenditure': return 'Current Expenditure'\n",
    "        if b == 'capital expenditure': return 'Capital Expenditure'\n",
    "        if b == 'total defence':\n",
    "            if split_pos is not None and pos >= split_pos:\n",
    "                return 'Total defence 2'   # economic-block total\n",
    "            else:\n",
    "                return 'Total defence 1'   # functional-block total\n",
    "        return None\n",
    "\n",
    "    df['line_final'] = [to_final_label(b, i) for i, b in enumerate(df['base'])]\n",
    "    df = df[df['line_final'].notna()]\n",
    "\n",
    "    # Long -> wide by FY\n",
    "    long = df.melt(id_vars='line_final', var_name='fy', value_name='value')\n",
    "    long['fy'] = long['fy'].astype(str).str.extract(r'(\\d{4}-\\d{2})')[0]\n",
    "    long = long[long['fy'].notna()]\n",
    "    long['value'] = pd.to_numeric(long['value'], errors='coerce')\n",
    "\n",
    "    out = (\n",
    "        long.pivot_table(index='fy', columns='line_final', values='value', aggfunc='first')\n",
    "            .reset_index()\n",
    "            .sort_values('fy')\n",
    "            .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Robust FY end-year calculation (handles 1999-00 -> 2000 correctly)\n",
    "    def _fy_endyear(fy):\n",
    "        m = re.match(r'(\\d{4})-(\\d{2})', str(fy))\n",
    "        if not m: return np.nan\n",
    "        y0 = int(m.group(1))\n",
    "        y2 = int(m.group(2))\n",
    "        century = y0 - (y0 % 100)\n",
    "        endy = century + y2\n",
    "        if endy < y0:\n",
    "            endy += 100\n",
    "        return endy\n",
    "\n",
    "    out['fy_endyear'] = out['fy'].apply(_fy_endyear)\n",
    "\n",
    "    # Ensure desired columns exist & order them\n",
    "    desired = [\n",
    "        'fy', 'fy_endyear',\n",
    "        'Military defence', 'Civil defence', 'Foreign military aid', 'R&D defence', 'Defence n.e.c.',\n",
    "        'Total defence 1', 'Current Expenditure', 'Capital Expenditure', 'Total defence 2'\n",
    "    ]\n",
    "    for c in desired:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "    out = out[desired]\n",
    "\n",
    "    # Strip plan years if present (keep outturns only) – optional\n",
    "    if len(out) >= 1:\n",
    "        maybe_last = out.iloc[-1]\n",
    "        if maybe_last[['Current Expenditure','Capital Expenditure','Total defence 2']].isna().any():\n",
    "            out = out.iloc[:-1].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) VALIDATION & TIDY ANNUAL\n",
    "# ----------------------------\n",
    "def validate_and_make_annual_tidy(df_wide, tolerance=5.0):\n",
    "    \"\"\"\n",
    "    df_wide: output of load_defence()\n",
    "    tolerance: acceptable absolute gap (in £ mn) for total ≈ current + capital\n",
    "    \"\"\"\n",
    "    df = df_wide.copy()\n",
    "\n",
    "    # Integrity checks\n",
    "    df['sum_econ'] = df['Current Expenditure'].fillna(0) + df['Capital Expenditure'].fillna(0)\n",
    "    df['gap_total_econ'] = (df['Total defence 2'] - df['sum_econ']).abs()\n",
    "\n",
    "    # Warn on rows that exceed tolerance\n",
    "    bad = df[df['gap_total_econ'] > tolerance]\n",
    "    if not bad.empty:\n",
    "        print(\"WARNING: Some fiscal years have Total != Current+Capital beyond tolerance.\")\n",
    "        display(bad[['fy','Total defence 2','Current Expenditure','Capital Expenditure','gap_total_econ']])\n",
    "\n",
    "    # Optional cross-check functional vs economic totals\n",
    "    if 'Total defence 1' in df.columns:\n",
    "        df['gap_total12'] = (df['Total defence 2'] - df['Total defence 1']).abs()\n",
    "        bad2 = df[df['gap_total12'] > tolerance]\n",
    "        if not bad2.empty:\n",
    "            print(\"NOTE: Functional vs economic totals differ beyond tolerance for some years (often rounding/classification).\")\n",
    "            display(bad2[['fy','Total defence 1','Total defence 2','gap_total12']])\n",
    "\n",
    "    # Build tidy annual (analysis core: total/current/capital, nominal)\n",
    "    tidy = (\n",
    "        df[['fy','fy_endyear','Total defence 2','Current Expenditure','Capital Expenditure']]\n",
    "        .rename(columns={'Total defence 2':'total_nom_mn',\n",
    "                         'Current Expenditure':'current_nom_mn',\n",
    "                         'Capital Expenditure':'capital_nom_mn'})\n",
    "        .melt(id_vars=['fy','fy_endyear'],\n",
    "              var_name='component', value_name='nominal_mn_gbp')\n",
    "    )\n",
    "    tidy['component'] = tidy['component'].str.replace('_nom_mn','', regex=False)\n",
    "    tidy['component'] = pd.Categorical(tidy['component'], ['total','current','capital'], ordered=True)\n",
    "\n",
    "    return tidy\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) FY → QUARTERS MAPPING\n",
    "# ----------------------------\n",
    "def fy_to_quarters(fy_str):\n",
    "    \"\"\"\n",
    "    Map FY 'YYYY-YY' to the 4 calendar quarters it spans:\n",
    "    FY 2004-05 -> ['2004Q2','2004Q3','2004Q4','2005Q1']\n",
    "    \"\"\"\n",
    "    y0 = int(fy_str.split('-')[0])\n",
    "    qtrs = [f\"{y0}Q2\", f\"{y0}Q3\", f\"{y0}Q4\", f\"{y0+1}Q1\"]\n",
    "    return qtrs\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) QUARTERISATION (indicator-proportional or equal ¼)\n",
    "# ----------------------------\n",
    "def quarterise_defence(tidy_annual, gdp_q=None):\n",
    "    \"\"\"\n",
    "    tidy_annual: output of validate_and_make_annual_tidy()\n",
    "    gdp_q: optional DataFrame with columns ['quarter','gdp_nom'] (YBHA, SA, £ mn)\n",
    "           If provided, each FY is allocated across its four quarters in proportion to GDP_nom shares.\n",
    "           If not, we allocate 25% to each quarter.\n",
    "\n",
    "    Returns: (q_nom_long, q_nom_wide)\n",
    "    \"\"\"\n",
    "    # Build a per-FY × quarter weight frame\n",
    "    weights_records = []\n",
    "    all_fy = tidy_annual['fy'].drop_duplicates().tolist()\n",
    "\n",
    "    if gdp_q is not None:\n",
    "        gdp_q = gdp_q.copy()\n",
    "        gdp_q['quarter'] = gdp_q['quarter'].astype(str)\n",
    "\n",
    "    for fy in all_fy:\n",
    "        qtrs = fy_to_quarters(fy)\n",
    "        if gdp_q is not None:\n",
    "            slice_q = gdp_q[gdp_q['quarter'].isin(qtrs)]\n",
    "            if slice_q.shape[0] == 4 and slice_q['gdp_nom'].notna().all() and slice_q['gdp_nom'].sum() > 0:\n",
    "                shares = (slice_q['gdp_nom'] / slice_q['gdp_nom'].sum()).values\n",
    "            else:\n",
    "                shares = np.array([0.25,0.25,0.25,0.25])\n",
    "        else:\n",
    "            shares = np.array([0.25,0.25,0.25,0.25])\n",
    "\n",
    "        for q, w in zip(qtrs, shares):\n",
    "            weights_records.append({'fy': fy, 'quarter': q, 'weight': float(w)})\n",
    "\n",
    "    weights = pd.DataFrame(weights_records)\n",
    "\n",
    "    # Allocate each FY × component across its four quarters using weights\n",
    "    q_nom = (tidy_annual\n",
    "             .merge(weights, on='fy', how='left')\n",
    "             .assign(nominal_q_mn=lambda d: d['nominal_mn_gbp'] * d['weight'])\n",
    "             [['quarter','component','nominal_q_mn']]\n",
    "            )\n",
    "\n",
    "    # Wide convenience version too\n",
    "    q_wide = (q_nom\n",
    "              .pivot_table(index='quarter', columns='component', values='nominal_q_mn', aggfunc='sum')\n",
    "              .reset_index()\n",
    "              .sort_values('quarter')\n",
    "             )\n",
    "    # Composition check (optional)\n",
    "    if set(['current','capital']).issubset(q_wide.columns):\n",
    "        q_wide['sum_econ'] = q_wide['current'].fillna(0) + q_wide['capital'].fillna(0)\n",
    "        if 'total' in q_wide.columns:\n",
    "            gap = (q_wide['total'] - q_wide['sum_econ']).abs()\n",
    "            if (gap > 1.0).any():\n",
    "                print(\"NOTE: At quarterly level, total != current+capital beyond £1m in some quarters (expected small rounding).\")\n",
    "\n",
    "    return q_nom, q_wide\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) OPTIONAL: DEFLATE QUARTERLY WITH YBGB\n",
    "# ----------------------------\n",
    "def deflate_quarterly(q_nom_long, deflator_q, base=100.0):\n",
    "    \"\"\"\n",
    "    q_nom_long: DataFrame with ['quarter','component','nominal_q_mn']\n",
    "    deflator_q: DataFrame with ['quarter','deflator_index'] (e.g., YBGB, SA)\n",
    "    base: ensure deflator is already in desired base; pass as-is.\n",
    "\n",
    "    Returns: long tidy quarterly with real series and logs.\n",
    "    \"\"\"\n",
    "    df = (q_nom_long.merge(deflator_q, on='quarter', how='left')\n",
    "                    .rename(columns={'deflator_index':'defl'}))\n",
    "    if df['defl'].isna().any():\n",
    "        missing = df[df['defl'].isna()]['quarter'].unique()[:10]\n",
    "        print(\"WARNING: Missing deflator for some quarters (showing up to 10):\", missing)\n",
    "\n",
    "    df['real_q_mn'] = df['nominal_q_mn'] / (df['defl'] / base)\n",
    "    df['ln_real'] = np.log(df['real_q_mn'].replace({0: np.nan}))\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6) RUN THE PIPELINE (reads from data/raw, writes to data/interim)\n",
    "# ----------------------------\n",
    "# Locate the defence workbook in /data/raw (handles different dash characters)\n",
    "defence_file = None\n",
    "for p in list(DATA_RAW.glob(\"*.xlsx\")) + list(DATA_RAW.glob(\"*.xls\")):\n",
    "    nm = p.name.lower().replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "    if (\"annual defence expenditure\" in nm and \"combined\" in nm) or \\\n",
    "       (\"annual_defence_expenditure\" in nm and \"combined\" in nm):\n",
    "        defence_file = p\n",
    "        break\n",
    "\n",
    "# Fallback to exact name if you prefer\n",
    "if defence_file is None:\n",
    "    fallback = DATA_RAW / \"Annual Defence Expenditure – Combined.xlsx\"\n",
    "    if fallback.exists():\n",
    "        defence_file = fallback\n",
    "\n",
    "if defence_file is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find 'Annual Defence Expenditure – Combined.xlsx' in data/raw. \"\n",
    "        \"Please place the file there (name can include hyphen/en dash).\"\n",
    "    )\n",
    "\n",
    "print(f\"Using defence workbook: {defence_file}\")\n",
    "\n",
    "# Load & clean\n",
    "df_wide = load_defence(defence_file)\n",
    "\n",
    "# Validate & produce tidy annual\n",
    "annual_tidy = validate_and_make_annual_tidy(df_wide, tolerance=5.0)\n",
    "\n",
    "# Save annual tidy to /data/interim\n",
    "annual_out = DATA_INTERIM / 'defence_fy_tidy.csv'\n",
    "annual_tidy.to_csv(annual_out, index=False)\n",
    "print(f\"Saved tidy annual to: {annual_out}\")\n",
    "\n",
    "# ---------- Quarterise ----------\n",
    "# OPTION A (recommended): pass quarterly nominal GDP (YBHA) for proportional allocation\n",
    "# If/when available in data/raw, load as below:\n",
    "# ybha_file = next((p for p in DATA_RAW.glob(\"series-*.csv\") if \"ybha\" in p.name.lower()), None)\n",
    "# if ybha_file:\n",
    "#     ybha_raw = pd.read_csv(ybha_file)\n",
    "#     gdp_q = (ybha_raw.rename(columns={'Period':'quarter','Value':'gdp_nom'})[['quarter','gdp_nom']])\n",
    "#     gdp_q['gdp_nom'] = pd.to_numeric(gdp_q['gdp_nom'], errors='coerce')\n",
    "# else:\n",
    "#     gdp_q = None\n",
    "\n",
    "gdp_q = None  # leave None for now; equal ¼ allocation\n",
    "\n",
    "q_nom_long, q_nom_wide = quarterise_defence(annual_tidy, gdp_q=gdp_q)\n",
    "\n",
    "# Save quarterly nominal to /data/interim\n",
    "q_nom_long_out = DATA_INTERIM / 'defence_q_nominal_long.csv'\n",
    "q_nom_wide_out = DATA_INTERIM / 'defence_q_nominal_wide.csv'\n",
    "q_nom_long.to_csv(q_nom_long_out, index=False)\n",
    "q_nom_wide.to_csv(q_nom_wide_out, index=False)\n",
    "print(f\"Saved quarterly nominal (long) to: {q_nom_long_out}\")\n",
    "print(f\"Saved quarterly nominal (wide) to: {q_nom_wide_out}\")\n",
    "\n",
    "# ---------- Deflate (optional; do this before modelling) ----------\n",
    "# If/when YBGB deflator CSV is in data/raw, load as below and then deflate:\n",
    "# ybgb_file = next((p for p in DATA_RAW.glob(\"series-*.csv\") if \"ybgb\" in p.name.lower()), None)\n",
    "# if ybgb_file:\n",
    "#     ybgb_raw = pd.read_csv(ybgb_file)\n",
    "#     deflator_q = (ybgb_raw.rename(columns={'Period':'quarter','Value':'deflator_index'})[['quarter','deflator_index']])\n",
    "#     deflator_q['deflator_index'] = pd.to_numeric(deflator_q['deflator_index'], errors='coerce')\n",
    "#     q_real_long = deflate_quarterly(q_nom_long, deflator_q, base=100.0)\n",
    "#     q_real_out = DATA_INTERIM / 'defence_q_real_long.csv'\n",
    "#     q_real_long.to_csv(q_real_out, index=False)\n",
    "#     print(f\"Saved quarterly REAL (long) to: {q_real_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b1e2c-3d35-41a0-bc76-cf97787c6ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8743fc30-46d4-4d41-bae2-92d5cab43c90",
   "metadata": {},
   "source": [
    "## 2) series-010725.csv (ONS code YBHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0726a66f-6a56-495c-b5e2-60e0b45c2575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Using YBHA source: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\series-010725.csv\n",
      "WARNING: FY coverage/weight-sum issues detected:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_quarters</th>\n",
       "      <th>weight_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-04</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-25</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_quarters  weight_sum\n",
       "fy                             \n",
       "2003-04           1         1.0\n",
       "2024-25           3         1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quarterly nominal GDP to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\ybha_q.csv\n",
      "Saved FY weights to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\ybha_fy_weights.csv\n",
      "\n",
      "Sample (quarterly GDP):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>gdp_nom_mn</th>\n",
       "      <th>cdid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004Q1</td>\n",
       "      <td>2004-03-31</td>\n",
       "      <td>322778</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004Q2</td>\n",
       "      <td>2004-06-30</td>\n",
       "      <td>329732</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004Q3</td>\n",
       "      <td>2004-09-30</td>\n",
       "      <td>331592</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004Q4</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>338535</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005Q1</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>341254</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005Q2</td>\n",
       "      <td>2005-06-30</td>\n",
       "      <td>348491</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005Q3</td>\n",
       "      <td>2005-09-30</td>\n",
       "      <td>352001</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005Q4</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>357003</td>\n",
       "      <td>YBHA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter quarter_end  gdp_nom_mn  cdid\n",
       "0  2004Q1  2004-03-31      322778  YBHA\n",
       "1  2004Q2  2004-06-30      329732  YBHA\n",
       "2  2004Q3  2004-09-30      331592  YBHA\n",
       "3  2004Q4  2004-12-31      338535  YBHA\n",
       "4  2005Q1  2005-03-31      341254  YBHA\n",
       "5  2005Q2  2005-06-30      348491  YBHA\n",
       "6  2005Q3  2005-09-30      352001  YBHA\n",
       "7  2005Q4  2005-12-31      357003  YBHA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (FY weights):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>quarter</th>\n",
       "      <th>gdp_nom_mn</th>\n",
       "      <th>fy_gdp_nom_sum</th>\n",
       "      <th>ybha_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-04</td>\n",
       "      <td>2004Q1</td>\n",
       "      <td>322778</td>\n",
       "      <td>322778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>2004Q2</td>\n",
       "      <td>329732</td>\n",
       "      <td>1341113</td>\n",
       "      <td>0.245864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>2004Q3</td>\n",
       "      <td>331592</td>\n",
       "      <td>1341113</td>\n",
       "      <td>0.247251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>2004Q4</td>\n",
       "      <td>338535</td>\n",
       "      <td>1341113</td>\n",
       "      <td>0.252428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>2005Q1</td>\n",
       "      <td>341254</td>\n",
       "      <td>1341113</td>\n",
       "      <td>0.254456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>2005Q2</td>\n",
       "      <td>348491</td>\n",
       "      <td>1418708</td>\n",
       "      <td>0.245640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>2005Q3</td>\n",
       "      <td>352001</td>\n",
       "      <td>1418708</td>\n",
       "      <td>0.248114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>2005Q4</td>\n",
       "      <td>357003</td>\n",
       "      <td>1418708</td>\n",
       "      <td>0.251640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fy quarter  gdp_nom_mn  fy_gdp_nom_sum  ybha_weight\n",
       "0  2003-04  2004Q1      322778          322778     1.000000\n",
       "1  2004-05  2004Q2      329732         1341113     0.245864\n",
       "2  2004-05  2004Q3      331592         1341113     0.247251\n",
       "3  2004-05  2004Q4      338535         1341113     0.252428\n",
       "4  2004-05  2005Q1      341254         1341113     0.254456\n",
       "5  2005-06  2005Q2      348491         1418708     0.245640\n",
       "6  2005-06  2005Q3      352001         1418708     0.248114\n",
       "7  2005-06  2005Q4      357003         1418708     0.251640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight sum check for FY 2003-04: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# ----------------------------\n",
    "# Project paths\n",
    "# ----------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "\n",
    "# ----------------------------\n",
    "# 0) CONFIG\n",
    "# ----------------------------\n",
    "# Find the YBHA file in data/raw (accepts e.g. 'series-010725.csv' or variants)\n",
    "ybha_file = DATA_RAW / \"series-010725.csv\"\n",
    "if not ybha_file.exists():\n",
    "    # fallback to any close match (e.g., duplicates like 'series-010725 (1).csv')\n",
    "    candidates = sorted(DATA_RAW.glob(\"series-010725*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find 'series-010725.csv' in data/raw.\")\n",
    "    ybha_file = candidates[0]\n",
    "\n",
    "print(f\"Using YBHA source: {ybha_file}\")\n",
    "\n",
    "# Analysis window (quarters, inclusive)\n",
    "ANALYSIS_START_Q = '2004Q1'   # keep Q1 so FY 2004-05 coverage (Q2–Q4 + next Q1) is possible\n",
    "ANALYSIS_END_Q   = '2024Q4'   # safe upper bound; you can trim later when merging\n",
    "\n",
    "# ----------------------------\n",
    "# 1) LOAD & PARSE (your logic, wrapped and extended)\n",
    "# ----------------------------\n",
    "def load_ons_single_series(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ONS 'single series' CSV (e.g., YBHA).\n",
    "    Returns tidy df with: period(str), value(float), year(int), quarter(Int64)\n",
    "    \"\"\"\n",
    "    text = path.read_text(encoding='utf-8', errors='ignore').splitlines()\n",
    "    rows = [next(csv.reader([ln])) for ln in text if ln.strip()]\n",
    "    data = [(r[0].strip('\"'), r[1]) for r in rows\n",
    "            if len(r) >= 2 and re.match(r'^\\d{4}(?:\\s+Q[1-4])?$', r[0].strip('\"'))]\n",
    "    df = pd.DataFrame(data, columns=['period', 'value'])\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df['year'] = df['period'].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['quarter'] = df['period'].str.extract(r'Q([1-4])').astype('Int64')\n",
    "    return df\n",
    "\n",
    "ybha = load_ons_single_series(ybha_file)\n",
    "\n",
    "# Keep QUARTERLY rows only; drop annual (not needed for weights)\n",
    "ybha_q = (ybha[ybha['quarter'].notna()]\n",
    "          .rename(columns={'value':'gdp_nom_mn'})\n",
    "          .copy()\n",
    "         )\n",
    "\n",
    "# Canonical quarter key and period end date\n",
    "ybha_q['quarter_key'] = ybha_q['year'].astype(int).astype(str) + 'Q' + ybha_q['quarter'].astype(int).astype(str)\n",
    "\n",
    "def quarter_end_date(y, q):\n",
    "    month = {1:3, 2:6, 3:9, 4:12}[int(q)]\n",
    "    return dt.date(int(y), month, 1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "ybha_q['quarter_end'] = [quarter_end_date(y, q) for y, q in zip(ybha_q['year'], ybha_q['quarter'])]\n",
    "\n",
    "# Trim to analysis window\n",
    "def qrank(qstr):  # e.g., 2004Q2 -> 2004*10 + 2\n",
    "    y, q = qstr.split('Q')\n",
    "    return int(y)*10 + int(q)\n",
    "\n",
    "mask = (ybha_q['quarter_key'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "       (ybha_q['quarter_key'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "ybha_q = ybha_q.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) MAP TO FISCAL YEARS & BUILD WITHIN-FY WEIGHTS\n",
    "# ----------------------------\n",
    "def to_fy(qkey: str) -> str:\n",
    "    y, q = qkey.split('Q')\n",
    "    y = int(y); q = int(q)\n",
    "    # FY runs Apr–Mar; Q2–Q4 belong to FY starting in that year; Q1 belongs to FY starting previous year\n",
    "    if q == 1:\n",
    "        fy_start = y - 1\n",
    "    else:\n",
    "        fy_start = y\n",
    "    fy_end_two = str((fy_start + 1) % 100).zfill(2)\n",
    "    return f\"{fy_start}-{fy_end_two}\"\n",
    "\n",
    "ybha_q['fy'] = ybha_q['quarter_key'].apply(to_fy)\n",
    "\n",
    "# FY totals and weights\n",
    "fy_totals = (ybha_q.groupby('fy', as_index=False)['gdp_nom_mn']\n",
    "             .sum().rename(columns={'gdp_nom_mn':'fy_gdp_nom_sum'}))\n",
    "\n",
    "ybha_w = (ybha_q.merge(fy_totals, on='fy', how='left')\n",
    "                .assign(ybha_weight=lambda d: d['gdp_nom_mn'] / d['fy_gdp_nom_sum'])\n",
    "                [['fy','quarter_key','gdp_nom_mn','fy_gdp_nom_sum','ybha_weight']]\n",
    "          )\n",
    "\n",
    "# Sanity: each FY should have exactly 4 quarters, weights sum to ~1\n",
    "check = (ybha_w.groupby('fy')\n",
    "         .agg(n_quarters=('quarter_key','nunique'),\n",
    "              weight_sum=('ybha_weight','sum')))\n",
    "bad_fy = check[(check['n_quarters'] != 4) | (check['weight_sum'].sub(1).abs() > 1e-6)]\n",
    "if not bad_fy.empty:\n",
    "    print(\"WARNING: FY coverage/weight-sum issues detected:\")\n",
    "    display(bad_fy.head(10))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) SAVE CLEAN OUTPUTS (to data/interim)\n",
    "# ----------------------------\n",
    "# 3a) Quarterly GDP (clean)\n",
    "ybha_q_out = (ybha_q[['quarter_key','quarter_end','gdp_nom_mn']]\n",
    "              .assign(cdid='YBHA')\n",
    "              .rename(columns={'quarter_key':'quarter'}))\n",
    "\n",
    "f_q = DATA_INTERIM / 'ybha_q.csv'\n",
    "ybha_q_out.to_csv(f_q, index=False)\n",
    "print(f\"Saved quarterly nominal GDP to: {f_q}\")\n",
    "\n",
    "# 3b) FY weights (for quarterising defence)\n",
    "ybha_w_out = ybha_w.rename(columns={'quarter_key':'quarter'})\n",
    "f_w = DATA_INTERIM / 'ybha_fy_weights.csv'\n",
    "ybha_w_out.to_csv(f_w, index=False)\n",
    "print(f\"Saved FY weights to: {f_w}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) OPTIONAL: QUICK DISPLAY / QA\n",
    "# ----------------------------\n",
    "print(\"\\nSample (quarterly GDP):\")\n",
    "display(ybha_q_out.head(8))\n",
    "print(\"Sample (FY weights):\")\n",
    "display(ybha_w_out.head(8))\n",
    "\n",
    "# Optional deeper QA: show one FY’s weights sum to 1\n",
    "if not ybha_w_out.empty:\n",
    "    ex_fy = ybha_w_out['fy'].iloc[0]\n",
    "    print(f\"Weight sum check for FY {ex_fy}:\",\n",
    "          ybha_w_out.query(\"fy == @ex_fy\")['ybha_weight'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e7040-1033-4dd5-b269-05ec9c24040e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31f6b704-2c76-45a3-82b5-9d99751ebd67",
   "metadata": {},
   "source": [
    "## 3) series-280625.csv (ONS code ABMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1b6da7-7951-4dc1-bf33-3fa78a573c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Using ABMI source: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\series-280625.csv\n",
      "ABMI sample after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>gdp_real_mn</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>ln_gdp_real</th>\n",
       "      <th>g_qoq_pct</th>\n",
       "      <th>g_yoy_pct</th>\n",
       "      <th>rec_tech</th>\n",
       "      <th>post_gfc</th>\n",
       "      <th>post_brexit</th>\n",
       "      <th>covid_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997 Q1</td>\n",
       "      <td>397303</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q1</td>\n",
       "      <td>1997-03-31</td>\n",
       "      <td>12.892454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997 Q2</td>\n",
       "      <td>401790</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q2</td>\n",
       "      <td>1997-06-30</td>\n",
       "      <td>12.903685</td>\n",
       "      <td>1.123035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997 Q3</td>\n",
       "      <td>405233</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q3</td>\n",
       "      <td>1997-09-30</td>\n",
       "      <td>12.912217</td>\n",
       "      <td>0.853265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997 Q4</td>\n",
       "      <td>411352</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q4</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>12.927205</td>\n",
       "      <td>1.498709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998 Q1</td>\n",
       "      <td>414377</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q1</td>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>12.934531</td>\n",
       "      <td>0.732689</td>\n",
       "      <td>4.207697</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998 Q2</td>\n",
       "      <td>416909</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q2</td>\n",
       "      <td>1998-06-30</td>\n",
       "      <td>12.940623</td>\n",
       "      <td>0.609179</td>\n",
       "      <td>3.693841</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998 Q3</td>\n",
       "      <td>418294</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q3</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>12.943940</td>\n",
       "      <td>0.331656</td>\n",
       "      <td>3.172232</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998 Q4</td>\n",
       "      <td>421074</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q4</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>12.950564</td>\n",
       "      <td>0.662406</td>\n",
       "      <td>2.335929</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  gdp_real_mn  year quarter quarter_end  ln_gdp_real  g_qoq_pct  \\\n",
       "0  1997 Q1       397303  1997  1997Q1  1997-03-31    12.892454        NaN   \n",
       "1  1997 Q2       401790  1997  1997Q2  1997-06-30    12.903685   1.123035   \n",
       "2  1997 Q3       405233  1997  1997Q3  1997-09-30    12.912217   0.853265   \n",
       "3  1997 Q4       411352  1997  1997Q4  1997-12-31    12.927205   1.498709   \n",
       "4  1998 Q1       414377  1998  1998Q1  1998-03-31    12.934531   0.732689   \n",
       "5  1998 Q2       416909  1998  1998Q2  1998-06-30    12.940623   0.609179   \n",
       "6  1998 Q3       418294  1998  1998Q3  1998-09-30    12.943940   0.331656   \n",
       "7  1998 Q4       421074  1998  1998Q4  1998-12-31    12.950564   0.662406   \n",
       "\n",
       "   g_yoy_pct  rec_tech  post_gfc  post_brexit  covid_window  \n",
       "0        NaN         0     False        False         False  \n",
       "1        NaN         0     False        False         False  \n",
       "2        NaN         0     False        False         False  \n",
       "3        NaN         0     False        False         False  \n",
       "4   4.207697         0     False        False         False  \n",
       "5   3.693841         0     False        False         False  \n",
       "6   3.172232         0     False        False         False  \n",
       "7   2.335929         0     False        False         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>gdp_real_mn</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>ln_gdp_real</th>\n",
       "      <th>g_qoq_pct</th>\n",
       "      <th>g_yoy_pct</th>\n",
       "      <th>rec_tech</th>\n",
       "      <th>post_gfc</th>\n",
       "      <th>post_brexit</th>\n",
       "      <th>covid_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023 Q2</td>\n",
       "      <td>634694</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q2</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>13.360898</td>\n",
       "      <td>0.041919</td>\n",
       "      <td>0.542834</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023 Q3</td>\n",
       "      <td>634327</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q3</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>13.360320</td>\n",
       "      <td>-0.057840</td>\n",
       "      <td>0.371159</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023 Q4</td>\n",
       "      <td>633011</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023Q4</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>13.358243</td>\n",
       "      <td>-0.207679</td>\n",
       "      <td>-0.163055</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024 Q1</td>\n",
       "      <td>638746</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q1</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>13.367262</td>\n",
       "      <td>0.901908</td>\n",
       "      <td>0.678307</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024 Q2</td>\n",
       "      <td>641670</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q2</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>13.371829</td>\n",
       "      <td>0.456727</td>\n",
       "      <td>1.093116</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2024 Q3</td>\n",
       "      <td>641675</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q3</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>13.371837</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>1.151735</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2024 Q4</td>\n",
       "      <td>642287</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>13.372791</td>\n",
       "      <td>0.095330</td>\n",
       "      <td>1.454744</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2025 Q1</td>\n",
       "      <td>646833</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025Q1</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>13.379843</td>\n",
       "      <td>0.705290</td>\n",
       "      <td>1.258127</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period  gdp_real_mn  year quarter quarter_end  ln_gdp_real  g_qoq_pct  \\\n",
       "105  2023 Q2       634694  2023  2023Q2  2023-06-30    13.360898   0.041919   \n",
       "106  2023 Q3       634327  2023  2023Q3  2023-09-30    13.360320  -0.057840   \n",
       "107  2023 Q4       633011  2023  2023Q4  2023-12-31    13.358243  -0.207679   \n",
       "108  2024 Q1       638746  2024  2024Q1  2024-03-31    13.367262   0.901908   \n",
       "109  2024 Q2       641670  2024  2024Q2  2024-06-30    13.371829   0.456727   \n",
       "110  2024 Q3       641675  2024  2024Q3  2024-09-30    13.371837   0.000779   \n",
       "111  2024 Q4       642287  2024  2024Q4  2024-12-31    13.372791   0.095330   \n",
       "112  2025 Q1       646833  2025  2025Q1  2025-03-31    13.379843   0.705290   \n",
       "\n",
       "     g_yoy_pct  rec_tech  post_gfc  post_brexit  covid_window  \n",
       "105   0.542834         0      True         True         False  \n",
       "106   0.371159         0      True         True         False  \n",
       "107  -0.163055         1      True         True         False  \n",
       "108   0.678307         0      True         True         False  \n",
       "109   1.093116         0      True         True         False  \n",
       "110   1.151735         0      True         True         False  \n",
       "111   1.454744         0      True         True         False  \n",
       "112   1.258127         0      True         True         False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned ABMI to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\abmi_q.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# ----------------------------\n",
    "# Project paths\n",
    "# ----------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "\n",
    "# ----------------------------\n",
    "# 0) CONFIG (now sourced from data/raw)\n",
    "# ----------------------------\n",
    "# Prefer exact name; fall back to close matches if needed\n",
    "abmi_file = DATA_RAW / \"series-280625.csv\"\n",
    "if not abmi_file.exists():\n",
    "    candidates = sorted(DATA_RAW.glob(\"series-280625*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find 'series-280625.csv' in data/raw.\")\n",
    "    abmi_file = candidates[0]\n",
    "print(f\"Using ABMI source: {abmi_file}\")\n",
    "\n",
    "ANALYSIS_START_Q = '1997Q1'   # generous buffer for lags/diagnostics\n",
    "ANALYSIS_END_Q   = '2025Q4'   # safe upper bound; you’ll trim to overlap later\n",
    "\n",
    "# ----------------------------\n",
    "# 1) LOAD & PARSE (your base, extended)\n",
    "# ----------------------------\n",
    "def load_ons_single_series(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an ONS 'single series' CSV (e.g., ABMI).\n",
    "    Returns tidy df with: period, value, year, quarter(Int64)\n",
    "    \"\"\"\n",
    "    text = p.read_text(encoding='utf-8', errors='ignore').splitlines()\n",
    "    rows = [next(csv.reader([ln])) for ln in text if ln.strip()]\n",
    "    # Keep \"YYYY\" or \"YYYY Qn\"\n",
    "    data = [(r[0].strip('\"'), r[1]) for r in rows\n",
    "            if len(r) >= 2 and re.match(r'^\\d{4}(?:\\s+Q[1-4])?$', r[0].strip('\"'))]\n",
    "    df = pd.DataFrame(data, columns=['period', 'value'])\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df['year'] = df['period'].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['quarter'] = df['period'].str.extract(r'Q([1-4])').astype('Int64')\n",
    "    return df\n",
    "\n",
    "abmi_raw = load_ons_single_series(abmi_file)\n",
    "\n",
    "# Keep QUARTERLY rows only (drop annual)\n",
    "abmi_q = (abmi_raw[abmi_raw['quarter'].notna()]\n",
    "          .rename(columns={'value':'gdp_real_mn'})\n",
    "          .copy())\n",
    "\n",
    "# Canonical quarter key\n",
    "abmi_q['quarter'] = (\n",
    "    abmi_q['year'].astype(int).astype(str) + 'Q' + abmi_q['quarter'].astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# End-of-quarter date (handy for plotting/joins)\n",
    "def quarter_end_date(qkey: str):\n",
    "    y, q = qkey.split('Q')\n",
    "    y = int(y); q = int(q)\n",
    "    month = {1:3, 2:6, 3:9, 4:12}[q]\n",
    "    return pd.Timestamp(year=y, month=month, day=1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "abmi_q['quarter_end'] = abmi_q['quarter'].apply(quarter_end_date)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) TRIM WINDOW & SORT\n",
    "# ----------------------------\n",
    "def qrank(qstr):  # e.g. 2004Q2 -> 20042\n",
    "    y, q = qstr.split('Q')\n",
    "    return int(y)*10 + int(q)\n",
    "\n",
    "mask = (abmi_q['quarter'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "       (abmi_q['quarter'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "abmi_q = abmi_q.loc[mask].sort_values('quarter').reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) DERIVED FIELDS (logs, growths, technical recession)\n",
    "# ----------------------------\n",
    "abmi_q['ln_gdp_real'] = np.log(abmi_q['gdp_real_mn'].replace({0: np.nan}))\n",
    "\n",
    "# log-diff growths (×100 for %)\n",
    "abmi_q['g_qoq_pct'] = 100 * (abmi_q['ln_gdp_real'] - abmi_q['ln_gdp_real'].shift(1))\n",
    "abmi_q['g_yoy_pct'] = 100 * (abmi_q['ln_gdp_real'] - abmi_q['ln_gdp_real'].shift(4))\n",
    "\n",
    "# Technical recession dummy: two consecutive negative q/q\n",
    "neg = (abmi_q['g_qoq_pct'] < 0).astype(int)\n",
    "abmi_q['rec_tech'] = ((neg.shift(0) == 1) & (neg.shift(1) == 1)).astype(int)\n",
    "\n",
    "# Optional period flags (convenient labels for splits)\n",
    "abmi_q['post_gfc']     = (abmi_q['quarter'].apply(qrank) >= qrank('2008Q3'))\n",
    "abmi_q['post_brexit']  = (abmi_q['quarter'].apply(qrank) >= qrank('2016Q3'))\n",
    "abmi_q['covid_window'] = (abmi_q['quarter'].apply(qrank) >= qrank('2020Q2')) & \\\n",
    "                         (abmi_q['quarter'].apply(qrank) <= qrank('2022Q1'))\n",
    "\n",
    "# ----------------------------\n",
    "# 4) QA CHECKS\n",
    "# ----------------------------\n",
    "# 4a) Duplicates / gaps\n",
    "dups = abmi_q.duplicated('quarter').sum()\n",
    "if dups:\n",
    "    print(f\"WARNING: {dups} duplicate quarter keys.\")\n",
    "\n",
    "# 4b) Missing values\n",
    "if abmi_q['gdp_real_mn'].isna().any():\n",
    "    print(\"WARNING: Missing ABMI values after parse/trim.\")\n",
    "\n",
    "# 4c) Quick sanity preview\n",
    "print(\"ABMI sample after cleaning:\")\n",
    "display(abmi_q.head(8))\n",
    "display(abmi_q.tail(8))\n",
    "\n",
    "# ----------------------------\n",
    "# 5) SAVE CLEAN OUTPUT (to data/interim)\n",
    "# ----------------------------\n",
    "out_cols = [\n",
    "    'quarter','quarter_end','gdp_real_mn','ln_gdp_real',\n",
    "    'g_qoq_pct','g_yoy_pct','rec_tech',\n",
    "    'post_gfc','post_brexit','covid_window'\n",
    "]\n",
    "abmi_out = abmi_q[out_cols].copy()\n",
    "\n",
    "f_out = DATA_INTERIM / 'abmi_q.csv'\n",
    "abmi_out.to_csv(f_out, index=False)\n",
    "print(f\"Saved cleaned ABMI to: {f_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af67ed-362e-4c0e-8626-d260f40d9c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e3e322-3386-428c-acd1-202f7468da4e",
   "metadata": {},
   "source": [
    "## 4) series-030725.csv (ONS code YBGB – GDP implied deflator index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8482f5-3a84-4a3a-82e0-31851ff01fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Using YBGB source: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\series-030725.csv\n",
      "FY-anchored variant skipped (set 'annex_f_csv' to a CSV with FY Annex-F deflators in data/raw).\n",
      "WARNING: Some FYs do not have exactly 4 quarters:\n",
      " fy\n",
      "1996-97    1\n",
      "Name: quarter, dtype: int64\n",
      "YBGB sample after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>deflator_index</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>ln_defl</th>\n",
       "      <th>pi_qoq_pct</th>\n",
       "      <th>pi_yoy_pct</th>\n",
       "      <th>fy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997 Q1</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q1</td>\n",
       "      <td>1997-03-31</td>\n",
       "      <td>4.070735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997 Q2</td>\n",
       "      <td>58.7</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q2</td>\n",
       "      <td>1997-06-30</td>\n",
       "      <td>4.072440</td>\n",
       "      <td>0.170503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997 Q3</td>\n",
       "      <td>60.1</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q3</td>\n",
       "      <td>1997-09-30</td>\n",
       "      <td>4.096010</td>\n",
       "      <td>2.357011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997 Q4</td>\n",
       "      <td>58.7</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997Q4</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>4.072440</td>\n",
       "      <td>-2.357011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998 Q1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q1</td>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>4.084294</td>\n",
       "      <td>1.185450</td>\n",
       "      <td>1.355953</td>\n",
       "      <td>1997-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998 Q2</td>\n",
       "      <td>59.5</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q2</td>\n",
       "      <td>1998-06-30</td>\n",
       "      <td>4.085976</td>\n",
       "      <td>0.168209</td>\n",
       "      <td>1.353659</td>\n",
       "      <td>1998-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998 Q3</td>\n",
       "      <td>59.9</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q3</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>4.092677</td>\n",
       "      <td>0.670019</td>\n",
       "      <td>-0.333334</td>\n",
       "      <td>1998-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998 Q4</td>\n",
       "      <td>60.3</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998Q4</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>4.099332</td>\n",
       "      <td>0.665560</td>\n",
       "      <td>2.689238</td>\n",
       "      <td>1998-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  deflator_index  year quarter quarter_end   ln_defl  pi_qoq_pct  \\\n",
       "0  1997 Q1            58.6  1997  1997Q1  1997-03-31  4.070735         NaN   \n",
       "1  1997 Q2            58.7  1997  1997Q2  1997-06-30  4.072440    0.170503   \n",
       "2  1997 Q3            60.1  1997  1997Q3  1997-09-30  4.096010    2.357011   \n",
       "3  1997 Q4            58.7  1997  1997Q4  1997-12-31  4.072440   -2.357011   \n",
       "4  1998 Q1            59.4  1998  1998Q1  1998-03-31  4.084294    1.185450   \n",
       "5  1998 Q2            59.5  1998  1998Q2  1998-06-30  4.085976    0.168209   \n",
       "6  1998 Q3            59.9  1998  1998Q3  1998-09-30  4.092677    0.670019   \n",
       "7  1998 Q4            60.3  1998  1998Q4  1998-12-31  4.099332    0.665560   \n",
       "\n",
       "   pi_yoy_pct       fy  \n",
       "0         NaN  1996-97  \n",
       "1         NaN  1997-98  \n",
       "2         NaN  1997-98  \n",
       "3         NaN  1997-98  \n",
       "4    1.355953  1997-98  \n",
       "5    1.353659  1998-99  \n",
       "6   -0.333334  1998-99  \n",
       "7    2.689238  1998-99  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as-published quarterly deflator to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\ybgb_q.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------------------------\n",
    "# Project paths\n",
    "# --------------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "\n",
    "# --------------------------------\n",
    "# 0) CONFIG — source files from data/raw\n",
    "# --------------------------------\n",
    "# Prefer exact name; fall back to close matches if needed\n",
    "ybgb_file = DATA_RAW / \"series-030725.csv\"\n",
    "if not ybgb_file.exists():\n",
    "    candidates = sorted(DATA_RAW.glob(\"series-030725*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find 'series-030725.csv' in data/raw.\")\n",
    "    ybgb_file = candidates[0]\n",
    "print(f\"Using YBGB source: {ybgb_file}\")\n",
    "\n",
    "# Optional: if you extract Annex F FY deflators to a CSV with columns: fy, annexF_deflator\n",
    "# (fy formatted like \"2004-05\"), put that CSV in data/raw and set its filename below.\n",
    "annex_f_csv = None  # e.g., \"annexF_deflators_fy.csv\"\n",
    "\n",
    "ANALYSIS_START_Q = '1997Q1'\n",
    "ANALYSIS_END_Q   = '2025Q4'\n",
    "\n",
    "# --------------------------------\n",
    "# 1) LOAD & PARSE\n",
    "# --------------------------------\n",
    "def load_ons_single_series(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an ONS 'single series' CSV (e.g., YBGB).\n",
    "    Returns tidy df with: period, value, year, quarter(Int64)\n",
    "    \"\"\"\n",
    "    text = p.read_text(encoding='utf-8', errors='ignore').splitlines()\n",
    "    rows = [next(csv.reader([ln])) for ln in text if ln.strip()]\n",
    "    data = [(r[0].strip('\"'), r[1]) for r in rows\n",
    "            if len(r) >= 2 and re.match(r'^\\d{4}(?:\\s+Q[1-4])?$', r[0].strip('\"'))]\n",
    "    df = pd.DataFrame(data, columns=['period', 'value'])\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')  # index value (e.g., CY=100)\n",
    "    df['year'] = df['period'].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['quarter'] = df['period'].str.extract(r'Q([1-4])').astype('Int64')\n",
    "    return df\n",
    "\n",
    "ybgb_raw = load_ons_single_series(ybgb_file)\n",
    "\n",
    "# Keep QUARTERLY only\n",
    "ybgb_q = (ybgb_raw[ybgb_raw['quarter'].notna()]\n",
    "          .rename(columns={'value':'deflator_index'})\n",
    "          .copy())\n",
    "\n",
    "# Canonical quarter key and end-of-quarter date\n",
    "ybgb_q['quarter'] = ybgb_q['year'].astype(str) + 'Q' + ybgb_q['quarter'].astype(int).astype(str)\n",
    "\n",
    "def quarter_end_date(qkey: str):\n",
    "    y, q = qkey.split('Q')\n",
    "    y = int(y); q = int(q)\n",
    "    month = {1:3, 2:6, 3:9, 4:12}[q]\n",
    "    return pd.Timestamp(year=y, month=month, day=1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "ybgb_q['quarter_end'] = ybgb_q['quarter'].apply(quarter_end_date)\n",
    "\n",
    "# Trim window\n",
    "def qrank(qstr):  # e.g. 2004Q2 -> 20042\n",
    "    y, q = qstr.split('Q')\n",
    "    return int(y)*10 + int(q)\n",
    "\n",
    "mask = (ybgb_q['quarter'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "       (ybgb_q['quarter'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "ybgb_q = ybgb_q.loc[mask].sort_values('quarter').reset_index(drop=True)\n",
    "\n",
    "# --------------------------------\n",
    "# 2) DIAGNOSTICS & FY MAPPING\n",
    "# --------------------------------\n",
    "# Inflation diagnostics (log-diff %)\n",
    "ybgb_q['ln_defl']    = np.log(ybgb_q['deflator_index'].replace({0: np.nan}))\n",
    "ybgb_q['pi_qoq_pct'] = 100 * (ybgb_q['ln_defl'] - ybgb_q['ln_defl'].shift(1))\n",
    "ybgb_q['pi_yoy_pct'] = 100 * (ybgb_q['ln_defl'] - ybgb_q['ln_defl'].shift(4))\n",
    "\n",
    "# Fiscal year mapping (Apr–Mar): FY YYYY-YY = Q2..Q4 of YYYY plus Q1 of YYYY+1\n",
    "def to_fy(qkey: str) -> str:\n",
    "    y, q = qkey.split('Q'); y = int(y); q = int(q)\n",
    "    fy_start = y - 1 if q == 1 else y\n",
    "    fy_end_two = str((fy_start + 1) % 100).zfill(2)\n",
    "    return f\"{fy_start}-{fy_end_two}\"\n",
    "\n",
    "ybgb_q['fy'] = ybgb_q['quarter'].apply(to_fy)\n",
    "\n",
    "# FY averages of YBGB (for checks/anchoring)\n",
    "fy_avg = (ybgb_q.groupby('fy', as_index=False)['deflator_index']\n",
    "          .mean().rename(columns={'deflator_index':'mean_ybgb_quarterly'}))\n",
    "\n",
    "# --------------------------------\n",
    "# 3) OPTIONAL: PESA-ANCHORED VARIANT (if Annex F FY deflators provided)\n",
    "# --------------------------------\n",
    "anchored = None\n",
    "fy_check = None\n",
    "\n",
    "if annex_f_csv is not None:\n",
    "    annex_path = DATA_RAW / annex_f_csv\n",
    "    if annex_path.exists():\n",
    "        annex = pd.read_csv(annex_path)\n",
    "        # Expect columns: fy, annexF_deflator\n",
    "        assert {'fy','annexF_deflator'}.issubset(annex.columns), \\\n",
    "            \"Annex-F CSV must have columns: fy, annexF_deflator\"\n",
    "        # Merge FY average YBGB with Annex F to get scaling factors by FY\n",
    "        fy_check = (fy_avg.merge(annex, on='fy', how='inner')\n",
    "                          .assign(scale_fy=lambda d: d['annexF_deflator'] / d['mean_ybgb_quarterly'],\n",
    "                                  ratio=lambda d: d['mean_ybgb_quarterly'] / d['annexF_deflator']))\n",
    "        # Apply FY-specific scale to each quarter in that FY\n",
    "        anchored = (ybgb_q.merge(fy_check[['fy','scale_fy']], on='fy', how='left')\n",
    "                         .assign(deflator_index_fyanchored=lambda d: d['deflator_index'] * d['scale_fy']))\n",
    "    else:\n",
    "        print(f\"FY-anchored variant skipped (Annex-F CSV not found: {annex_path})\")\n",
    "else:\n",
    "    print(\"FY-anchored variant skipped (set 'annex_f_csv' to a CSV with FY Annex-F deflators in data/raw).\")\n",
    "\n",
    "# --------------------------------\n",
    "# 4) QA\n",
    "# --------------------------------\n",
    "# Contiguity per FY (should be 4 quarters)\n",
    "fy_counts = ybgb_q.groupby('fy')['quarter'].nunique()\n",
    "bad_fy = fy_counts[fy_counts != 4]\n",
    "if not bad_fy.empty:\n",
    "    print(\"WARNING: Some FYs do not have exactly 4 quarters:\\n\", bad_fy)\n",
    "\n",
    "# Quick preview\n",
    "print(\"YBGB sample after cleaning:\")\n",
    "display(ybgb_q.head(8))\n",
    "\n",
    "# --------------------------------\n",
    "# 5) SAVE OUTPUTS (to data/interim)\n",
    "# --------------------------------\n",
    "# 5a) As-published quarterly deflator\n",
    "ybgb_out = ybgb_q[['quarter','quarter_end','deflator_index','pi_qoq_pct','pi_yoy_pct','fy']]\n",
    "f_q = DATA_INTERIM / 'ybgb_q.csv'\n",
    "ybgb_out.to_csv(f_q, index=False)\n",
    "print(f\"Saved as-published quarterly deflator to: {f_q}\")\n",
    "\n",
    "# 5b) FY-anchored quarterly deflator (if available)\n",
    "if anchored is not None:\n",
    "    ybgb_anch = anchored[['quarter','fy','deflator_index_fyanchored']]\n",
    "    f_a = DATA_INTERIM / 'ybgb_q_fyanchored.csv'\n",
    "    ybgb_anch.to_csv(f_a, index=False)\n",
    "    print(f\"Saved FY-anchored quarterly deflator to: {f_a}\")\n",
    "    # FY check table\n",
    "    if fy_check is not None:\n",
    "        f_check = DATA_INTERIM / 'ybgb_fy_check.csv'\n",
    "        fy_check.to_csv(f_check, index=False)\n",
    "        print(f\"Saved FY anchoring check table to: {f_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b165f-871a-44ab-a951-8464f418bc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a56f35f5-ed98-4d07-95ef-d2f200ffbcd2",
   "metadata": {},
   "source": [
    "## 5) series-030725 (1).csv (ONS code L522 – CPIH index, 2015=100, monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a766b-1905-4468-9fda-c5e885b4016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Using CPIH (L522) source: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\series-030725 (1).csv\n",
      "Saved CPIH monthly to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\cpih_monthly.csv\n",
      "Note: Latest quarter is partial (fewer than 3 months). Consider excluding from estimation.\n",
      "Saved CPIH quarterly to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\cpih_quarterly.csv\n",
      "\n",
      "Monthly sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>month_end</th>\n",
       "      <th>cpih_idx</th>\n",
       "      <th>inf_yoy_pct_m</th>\n",
       "      <th>inf_mom_pct_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988-01</td>\n",
       "      <td>1988-01-31</td>\n",
       "      <td>46.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988-02</td>\n",
       "      <td>1988-02-29</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988-03</td>\n",
       "      <td>1988-03-31</td>\n",
       "      <td>47.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988-04</td>\n",
       "      <td>1988-04-30</td>\n",
       "      <td>47.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.263175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988-05</td>\n",
       "      <td>1988-05-31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1988-06</td>\n",
       "      <td>1988-06-30</td>\n",
       "      <td>48.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.415801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1988-07</td>\n",
       "      <td>1988-07-31</td>\n",
       "      <td>48.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988-08</td>\n",
       "      <td>1988-08-31</td>\n",
       "      <td>48.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1988-09</td>\n",
       "      <td>1988-09-30</td>\n",
       "      <td>48.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.411523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1988-10</td>\n",
       "      <td>1988-10-31</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1988-11</td>\n",
       "      <td>1988-11-30</td>\n",
       "      <td>49.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1988-12</td>\n",
       "      <td>1988-12-31</td>\n",
       "      <td>49.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  month_end  cpih_idx  inf_yoy_pct_m  inf_mom_pct_m\n",
       "0   1988-01 1988-01-31      46.9            NaN            NaN\n",
       "1   1988-02 1988-02-29      47.0            NaN       0.212993\n",
       "2   1988-03 1988-03-31      47.2            NaN       0.424629\n",
       "3   1988-04 1988-04-30      47.8            NaN       1.263175\n",
       "4   1988-05 1988-05-31      48.0            NaN       0.417537\n",
       "5   1988-06 1988-06-30      48.2            NaN       0.415801\n",
       "6   1988-07 1988-07-31      48.2            NaN       0.000000\n",
       "7   1988-08 1988-08-31      48.5            NaN       0.620478\n",
       "8   1988-09 1988-09-30      48.7            NaN       0.411523\n",
       "9   1988-10 1988-10-31      49.0            NaN       0.614127\n",
       "10  1988-11 1988-11-30      49.3            NaN       0.610378\n",
       "11  1988-12 1988-12-31      49.3            NaN       0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarterly sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>cpih_idx_q</th>\n",
       "      <th>inf_qoq_pct_q</th>\n",
       "      <th>inf_yoy_pct_q</th>\n",
       "      <th>is_partial_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997Q1</td>\n",
       "      <td>1997-03-31</td>\n",
       "      <td>69.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997Q2</td>\n",
       "      <td>1997-06-30</td>\n",
       "      <td>69.933333</td>\n",
       "      <td>0.909750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997Q3</td>\n",
       "      <td>1997-09-30</td>\n",
       "      <td>70.266667</td>\n",
       "      <td>0.475512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997Q4</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>70.633333</td>\n",
       "      <td>0.520465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998Q1</td>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>70.600000</td>\n",
       "      <td>-0.047203</td>\n",
       "      <td>1.858524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998Q2</td>\n",
       "      <td>1998-06-30</td>\n",
       "      <td>71.366667</td>\n",
       "      <td>1.080076</td>\n",
       "      <td>2.028850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998Q3</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>71.433333</td>\n",
       "      <td>0.093371</td>\n",
       "      <td>1.646709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998Q4</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>71.833333</td>\n",
       "      <td>0.558401</td>\n",
       "      <td>1.684644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter quarter_end  cpih_idx_q  inf_qoq_pct_q  inf_yoy_pct_q  is_partial_q\n",
       "0  1997Q1  1997-03-31   69.300000            NaN            NaN             0\n",
       "1  1997Q2  1997-06-30   69.933333       0.909750            NaN             0\n",
       "2  1997Q3  1997-09-30   70.266667       0.475512            NaN             0\n",
       "3  1997Q4  1997-12-31   70.633333       0.520465            NaN             0\n",
       "4  1998Q1  1998-03-31   70.600000      -0.047203       1.858524             0\n",
       "5  1998Q2  1998-06-30   71.366667       1.080076       2.028850             0\n",
       "6  1998Q3  1998-09-30   71.433333       0.093371       1.646709             0\n",
       "7  1998Q4  1998-12-31   71.833333       0.558401       1.684644             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re, calendar, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------------------------\n",
    "# Project paths\n",
    "# --------------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "\n",
    "# --------------------------------\n",
    "# 0) CONFIG — source from data/raw\n",
    "# --------------------------------\n",
    "# Prefer exact name; fall back to close matches if needed\n",
    "cpih_file = DATA_RAW / \"series-030725 (1).csv\"\n",
    "if not cpih_file.exists():\n",
    "    candidates = sorted(DATA_RAW.glob(\"series-030725*1*.csv\")) or \\\n",
    "                 sorted(DATA_RAW.glob(\"series-030725*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find 'series-030725 (1).csv' in data/raw.\")\n",
    "    cpih_file = candidates[0]\n",
    "print(f\"Using CPIH (L522) source: {cpih_file}\")\n",
    "\n",
    "ANALYSIS_START_Q = '1997Q1'   # generous buffer\n",
    "ANALYSIS_END_Q   = '2025Q4'   # safe cap; final merge will align windows\n",
    "\n",
    "# --------------------------------\n",
    "# 1) HELPERS (your parser, extended)\n",
    "# --------------------------------\n",
    "def parse_period_monthly(s: str):\n",
    "    \"\"\"\n",
    "    Parse a monthly ONS period string into (year, month).\n",
    "    Accepts '1988 JAN', '1988 January', '1988-01', '1988 01', '1988/01', '1988-Jan'.\n",
    "    \"\"\"\n",
    "    s = s.strip().strip('\"').replace('\\u00a0', ' ')\n",
    "    for fmt in (\"%Y %b\", \"%Y %B\", \"%Y-%m\", \"%Y %m\", \"%Y/%m\", \"%Y-%b\", \"%Y/%b\"):\n",
    "        try:\n",
    "            dtm = datetime.strptime(s, fmt)\n",
    "            return dtm.year, dtm.month\n",
    "        except Exception:\n",
    "            pass\n",
    "    m = re.match(r'^(\\d{4})\\s+([A-Za-z]{3,})$', s)\n",
    "    if m:\n",
    "        year = int(m.group(1))\n",
    "        mon_name = m.group(2).capitalize()\n",
    "        month_map = {name: i for i, name in enumerate(calendar.month_name) if name}\n",
    "        month_map.update({name: i for i, name in enumerate(calendar.month_abbr) if name})\n",
    "        if mon_name in month_map:\n",
    "            return year, month_map[mon_name]\n",
    "    m = re.match(r'^(\\d{4})[-/](\\d{1,2})$', s) or re.match(r'^(\\d{4})\\s+(\\d{1,2})$', s)\n",
    "    if m:\n",
    "        return int(m.group(1)), int(m.group(2))\n",
    "    return None, None\n",
    "\n",
    "def load_ons_single_series_monthly(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ONS 'single series' CSV (monthly). Return tidy monthly df.\n",
    "    Columns: period, cpih_idx, year, month, month_end\n",
    "    \"\"\"\n",
    "    lines = p.read_text(encoding='utf-8', errors='ignore').splitlines()\n",
    "    rows = [next(csv.reader([ln])) for ln in lines if ln.strip()]\n",
    "\n",
    "    # Keep rows that likely hold data (start with a year)\n",
    "    data = [(r[0].strip(), r[1]) for r in rows if len(r) >= 2 and re.match(r'^\\s*\"?\\d{4}', r[0])]\n",
    "    periods, values, years, months = [], [], [], []\n",
    "    for pstr, val in data:\n",
    "        y, m = parse_period_monthly(pstr)\n",
    "        if y is None or m is None:\n",
    "            continue\n",
    "        periods.append(pstr.strip().strip('\"'))\n",
    "        values.append(val)\n",
    "        years.append(y)\n",
    "        months.append(m)\n",
    "\n",
    "    df = pd.DataFrame({'period': periods, 'cpih_idx': values, 'year': years, 'month': months})\n",
    "    df['cpih_idx'] = pd.to_numeric(df['cpih_idx'], errors='coerce')\n",
    "    df['month_end'] = pd.to_datetime(df[['year', 'month']].assign(day=1)) + pd.offsets.MonthEnd(0)\n",
    "    df = df.sort_values(['year', 'month']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def qkey_from_date(ts: pd.Timestamp) -> str:\n",
    "    q = (ts.month - 1)//3 + 1\n",
    "    return f\"{ts.year}Q{q}\"\n",
    "\n",
    "def qrank(qstr: str) -> int:\n",
    "    y, q = qstr.split('Q')\n",
    "    return int(y)*10 + int(q)\n",
    "\n",
    "def quarter_end_date_from_key(qkey: str) -> pd.Timestamp:\n",
    "    y, q = qkey.split('Q'); y = int(y); q = int(q)\n",
    "    month = {1:3, 2:6, 3:9, 4:12}[q]\n",
    "    return pd.Timestamp(year=y, month=month, day=1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# --------------------------------\n",
    "# 2) LOAD MONTHLY + DIAGNOSTICS\n",
    "# --------------------------------\n",
    "cpih_m = load_ons_single_series_monthly(cpih_file)\n",
    "\n",
    "# Monthly YoY (prefer for charts; MoM optional)\n",
    "cpih_m['ln_idx'] = np.log(cpih_m['cpih_idx'].replace({0: np.nan}))\n",
    "cpih_m['inf_yoy_pct_m'] = 100 * (cpih_m['ln_idx'] - cpih_m['ln_idx'].shift(12))\n",
    "cpih_m['inf_mom_pct_m'] = 100 * (cpih_m['ln_idx'] - cpih_m['ln_idx'].shift(1))\n",
    "\n",
    "# Save monthly file (QA/plots) -> data/interim\n",
    "cpih_monthly_out = cpih_m[['period','month_end','cpih_idx','inf_yoy_pct_m','inf_mom_pct_m']].copy()\n",
    "cpih_monthly_out['month'] = cpih_monthly_out['month_end'].dt.strftime('%Y-%m')\n",
    "cpih_monthly_out = cpih_monthly_out[['month','month_end','cpih_idx','inf_yoy_pct_m','inf_mom_pct_m']]\n",
    "f_m = DATA_INTERIM / 'cpih_monthly.csv'\n",
    "cpih_monthly_out.to_csv(f_m, index=False)\n",
    "print(f\"Saved CPIH monthly to: {f_m}\")\n",
    "\n",
    "# --------------------------------\n",
    "# 3) AGGREGATE TO QUARTERS (analysis dataset)\n",
    "# --------------------------------\n",
    "cpih_m['quarter'] = cpih_m['month_end'].apply(qkey_from_date)\n",
    "# Average index over 3 months per quarter (robust standard)\n",
    "q_agg = (cpih_m.groupby('quarter', as_index=False)\n",
    "         .agg(cpih_idx_q=('cpih_idx','mean'),\n",
    "              n_months=('cpih_idx','size')))\n",
    "\n",
    "# Partial-quarter flag\n",
    "q_agg['is_partial_q'] = (q_agg['n_months'] < 3).astype(int)\n",
    "\n",
    "# Add quarter_end and sort\n",
    "q_agg['quarter_end'] = q_agg['quarter'].apply(quarter_end_date_from_key)\n",
    "q_agg = q_agg.sort_values('quarter').reset_index(drop=True)\n",
    "\n",
    "# Trim window\n",
    "mask = (q_agg['quarter'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "       (q_agg['quarter'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "q_agg = q_agg.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# Quarterly inflation rates (YoY preferred for modelling; QoQ optional)\n",
    "q_agg['ln_idx_q'] = np.log(q_agg['cpih_idx_q'].replace({0: np.nan}))\n",
    "q_agg['inf_qoq_pct_q'] = 100 * (q_agg['ln_idx_q'] - q_agg['ln_idx_q'].shift(1))\n",
    "q_agg['inf_yoy_pct_q'] = 100 * (q_agg['ln_idx_q'] - q_agg['ln_idx_q'].shift(4))\n",
    "\n",
    "# Final quarterly output\n",
    "cpih_quarterly_out = q_agg[['quarter','quarter_end','cpih_idx_q','inf_qoq_pct_q','inf_yoy_pct_q','is_partial_q']].copy()\n",
    "\n",
    "# Warn if last quarter is partial; you’ll typically drop partials in modelling\n",
    "if not cpih_quarterly_out.empty and cpih_quarterly_out['is_partial_q'].iloc[-1] == 1:\n",
    "    print(\"Note: Latest quarter is partial (fewer than 3 months). Consider excluding from estimation.\")\n",
    "\n",
    "# Save quarterly file -> data/interim\n",
    "f_q = DATA_INTERIM / 'cpih_quarterly.csv'\n",
    "cpih_quarterly_out.to_csv(f_q, index=False)\n",
    "print(f\"Saved CPIH quarterly to: {f_q}\")\n",
    "\n",
    "# --------------------------------\n",
    "# 4) QUICK PREVIEWS\n",
    "# --------------------------------\n",
    "print(\"\\nMonthly sample:\")\n",
    "display(cpih_monthly_out.head(12))\n",
    "print(\"Quarterly sample:\")\n",
    "display(cpih_quarterly_out.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77dd57-7ecc-457d-907b-df655d08c2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4bed3b1-2a48-4dae-b513-8a7ae85e7fb4",
   "metadata": {},
   "source": [
    "## 6) series-030725 (2).csv (ONS code EBAQ – UK resident population; “Qtly data interpolated”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9b4f0d-9f38-47cc-9380-57dd5fc51795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\n",
      "Raw: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\n",
      "Interim: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\n",
      "Using EBAQ source: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\raw\\series-030725 (2).csv\n",
      "Note: MYE workbook not found in data/raw (optional). Splice will be skipped if not needed.\n",
      "Saved population (quarterly) to: C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\interim\\pop_q.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>pop_thous</th>\n",
       "      <th>pop_persons</th>\n",
       "      <th>ln_pop</th>\n",
       "      <th>pop_yoy_pct</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997Q1</td>\n",
       "      <td>1997-03-31</td>\n",
       "      <td>58277</td>\n",
       "      <td>58277000.0</td>\n",
       "      <td>17.880718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997Q2</td>\n",
       "      <td>1997-06-30</td>\n",
       "      <td>58314</td>\n",
       "      <td>58314000.0</td>\n",
       "      <td>17.881353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997Q3</td>\n",
       "      <td>1997-09-30</td>\n",
       "      <td>58354</td>\n",
       "      <td>58354000.0</td>\n",
       "      <td>17.882038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997Q4</td>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>58395</td>\n",
       "      <td>58395000.0</td>\n",
       "      <td>17.882741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998Q1</td>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>58435</td>\n",
       "      <td>58435000.0</td>\n",
       "      <td>17.883426</td>\n",
       "      <td>0.270752</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998Q2</td>\n",
       "      <td>1998-06-30</td>\n",
       "      <td>58475</td>\n",
       "      <td>58475000.0</td>\n",
       "      <td>17.884110</td>\n",
       "      <td>0.275711</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998Q3</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>58527</td>\n",
       "      <td>58527000.0</td>\n",
       "      <td>17.884999</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998Q4</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>58580</td>\n",
       "      <td>58580000.0</td>\n",
       "      <td>17.885904</td>\n",
       "      <td>0.316307</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter quarter_end  pop_thous  pop_persons     ln_pop  pop_yoy_pct source\n",
       "0  1997Q1  1997-03-31      58277   58277000.0  17.880718          NaN   EBAQ\n",
       "1  1997Q2  1997-06-30      58314   58314000.0  17.881353          NaN   EBAQ\n",
       "2  1997Q3  1997-09-30      58354   58354000.0  17.882038          NaN   EBAQ\n",
       "3  1997Q4  1997-12-31      58395   58395000.0  17.882741          NaN   EBAQ\n",
       "4  1998Q1  1998-03-31      58435   58435000.0  17.883426     0.270752   EBAQ\n",
       "5  1998Q2  1998-06-30      58475   58475000.0  17.884110     0.275711   EBAQ\n",
       "6  1998Q3  1998-09-30      58527   58527000.0  17.884999     0.296028   EBAQ\n",
       "7  1998Q4  1998-12-31      58580   58580000.0  17.885904     0.316307   EBAQ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>quarter_end</th>\n",
       "      <th>pop_thous</th>\n",
       "      <th>pop_persons</th>\n",
       "      <th>ln_pop</th>\n",
       "      <th>pop_yoy_pct</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023Q1</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>68270</td>\n",
       "      <td>68270000.0</td>\n",
       "      <td>18.038981</td>\n",
       "      <td>1.209867</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023Q2</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>68492</td>\n",
       "      <td>68492000.0</td>\n",
       "      <td>18.042228</td>\n",
       "      <td>1.304980</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023Q3</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>68676</td>\n",
       "      <td>68676000.0</td>\n",
       "      <td>18.044910</td>\n",
       "      <td>1.245419</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023Q4</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>68859</td>\n",
       "      <td>68859000.0</td>\n",
       "      <td>18.047571</td>\n",
       "      <td>1.184760</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024Q1</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>69043</td>\n",
       "      <td>69043000.0</td>\n",
       "      <td>18.050240</td>\n",
       "      <td>1.125907</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024Q2</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>69226</td>\n",
       "      <td>69226000.0</td>\n",
       "      <td>18.052887</td>\n",
       "      <td>1.065956</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2024Q3</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>69387</td>\n",
       "      <td>69387000.0</td>\n",
       "      <td>18.055210</td>\n",
       "      <td>1.029974</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2024Q4</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>69547</td>\n",
       "      <td>69547000.0</td>\n",
       "      <td>18.057513</td>\n",
       "      <td>0.994185</td>\n",
       "      <td>EBAQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quarter quarter_end  pop_thous  pop_persons     ln_pop  pop_yoy_pct source\n",
       "104  2023Q1  2023-03-31      68270   68270000.0  18.038981     1.209867   EBAQ\n",
       "105  2023Q2  2023-06-30      68492   68492000.0  18.042228     1.304980   EBAQ\n",
       "106  2023Q3  2023-09-30      68676   68676000.0  18.044910     1.245419   EBAQ\n",
       "107  2023Q4  2023-12-31      68859   68859000.0  18.047571     1.184760   EBAQ\n",
       "108  2024Q1  2024-03-31      69043   69043000.0  18.050240     1.125907   EBAQ\n",
       "109  2024Q2  2024-06-30      69226   69226000.0  18.052887     1.065956   EBAQ\n",
       "110  2024Q3  2024-09-30      69387   69387000.0  18.055210     1.029974   EBAQ\n",
       "111  2024Q4  2024-12-31      69547   69547000.0  18.057513     0.994185   EBAQ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Project paths\n",
    "# ------------------------------------------------------------\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_RAW = PROJ_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_INTERIM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJ_ROOT)\n",
    "print(\"Raw:\", DATA_RAW)\n",
    "print(\"Interim:\", DATA_INTERIM)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) CONFIG — source files from data/raw\n",
    "# ------------------------------------------------------------\n",
    "# Prefer exact names; fall back to close matches if needed\n",
    "ebaq_file = DATA_RAW / \"series-030725 (2).csv\"\n",
    "if not ebaq_file.exists():\n",
    "    candidates = sorted(DATA_RAW.glob(\"series-030725*2*.csv\")) or \\\n",
    "                 sorted(DATA_RAW.glob(\"series-030725*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find 'series-030725 (2).csv' in data/raw.\")\n",
    "    ebaq_file = candidates[0]\n",
    "print(f\"Using EBAQ source: {ebaq_file}\")\n",
    "\n",
    "# Optional: ONS MYE workbook to splice 2022–2023 anchors (UK total population)\n",
    "mye_file = DATA_RAW / \"ukpopulationestimates183820231.xlsx\"\n",
    "if not mye_file.exists():\n",
    "    # allow running without MYE; splice will be skipped unless needed\n",
    "    print(\"Note: MYE workbook not found in data/raw (optional). Splice will be skipped if not needed.\")\n",
    "\n",
    "ANALYSIS_START_Q = '1997Q1'   # generous buffer\n",
    "ANALYSIS_END_Q   = '2025Q4'   # safe cap; final merge will align windows\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) HELPERS\n",
    "# ------------------------------------------------------------\n",
    "def load_ons_single_series(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an ONS single-series CSV (annual and/or quarterly lines).\n",
    "    Returns columns: period, value, year, q (Int64, may be NA).\n",
    "    \"\"\"\n",
    "    text = path.read_text(encoding='utf-8', errors='ignore').splitlines()\n",
    "    rows = [next(csv.reader([ln])) for ln in text if ln.strip()]\n",
    "    data = [(r[0].strip('\"'), r[1]) for r in rows\n",
    "            if len(r) >= 2 and re.match(r'^\\d{4}(?:\\s+Q[1-4])?$', r[0].strip('\"'))]\n",
    "    if not data:\n",
    "        raise ValueError(\"No ONS data rows found (expected 'YYYY' or 'YYYY Qn').\")\n",
    "    df = pd.DataFrame(data, columns=['period','value'])\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df['year']  = df['period'].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['q']     = df['period'].str.extract(r'Q([1-4])').astype('Int64')\n",
    "    return df\n",
    "\n",
    "def qkey(y:int, q:int) -> str:\n",
    "    return f\"{y}Q{q}\"\n",
    "\n",
    "def q_from_key(qk:str):\n",
    "    y, q = qk.split('Q'); return int(y), int(q)\n",
    "\n",
    "def q_end_date(qk:str) -> pd.Timestamp:\n",
    "    y, q = q_from_key(qk)\n",
    "    month = {1:3, 2:6, 3:9, 4:12}[q]\n",
    "    return pd.Timestamp(year=y, month=month, day=1) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "def qrank(qk:str) -> int:\n",
    "    y,q = q_from_key(qk); return y*10 + q\n",
    "\n",
    "def q_range(q_start:str, q_end:str):\n",
    "    s = qrank(q_start); e = qrank(q_end)\n",
    "    if e < s: return []\n",
    "    out = []\n",
    "    for r in range(s, e+1):\n",
    "        y, q = divmod(r, 10)\n",
    "        out.append(qkey(y, q))\n",
    "    return out\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) LOAD EBAQ AND KEEP QUARTERLY\n",
    "# ------------------------------------------------------------\n",
    "ebaq_raw = load_ons_single_series(ebaq_file)\n",
    "\n",
    "# Keep only quarterly rows (drop annual if present)\n",
    "ebaq_q = ebaq_raw[ebaq_raw['q'].notna()].copy()\n",
    "if ebaq_q.empty:\n",
    "    raise ValueError(\"This EBAQ file appears to contain only annual values. \"\n",
    "                     \"Please download the quarterly-interpolated EBAQ series (YYYY Qn rows).\")\n",
    "\n",
    "# Canonical quarter key and end date\n",
    "ebaq_q['quarter'] = ebaq_q.apply(lambda r: qkey(int(r['year']), int(r['q'])), axis=1)\n",
    "ebaq_q['quarter_end'] = ebaq_q['quarter'].apply(q_end_date)\n",
    "\n",
    "# Units: EBAQ is typically in THOUSANDS of persons\n",
    "ebaq_q = ebaq_q.rename(columns={'value':'pop_thous'})\n",
    "ebaq_q['source'] = 'EBAQ'\n",
    "\n",
    "# Trim window and sort\n",
    "mask = (ebaq_q['quarter'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "       (ebaq_q['quarter'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "ebaq_q = ebaq_q.loc[mask].sort_values('quarter').reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) OPTIONAL SPLICE 2022–2023 USING MYE ANCHORS (Q2 each year)\n",
    "# ------------------------------------------------------------\n",
    "def read_mye_uk_totals(mye_xlsx: Path):\n",
    "    \"\"\"\n",
    "    Tries to read UK total population for 2022 and 2023 from the MYE workbook.\n",
    "    Returns a dict {2022: value_thous, 2023: value_thous} or {} if not found.\n",
    "    The workbook formats vary; this scans all sheets for a row containing 'United Kingdom'\n",
    "    and numeric year columns.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    try:\n",
    "        xls = pd.read_excel(mye_xlsx, sheet_name=None, header=None)\n",
    "    except Exception as e:\n",
    "        print(f\"MYE workbook not read ({e}). Skipping splice.\")\n",
    "        return out\n",
    "\n",
    "    for name, sh in xls.items():\n",
    "        df = sh.copy()\n",
    "        # Try to locate a row containing 'United Kingdom' (case-insensitive)\n",
    "        mask_row = df.apply(lambda r: r.astype(str).str.contains('United Kingdom', case=False, na=False).any(), axis=1)\n",
    "        if not mask_row.any():\n",
    "            continue\n",
    "        # Promote the first non-empty row above as header if likely\n",
    "        header_idx = None\n",
    "        for i in range(min(10, len(df))):\n",
    "            vals = df.iloc[i].tolist()\n",
    "            years_found = sum([1 for v in vals if str(v).strip().isdigit() and 1800 <= int(str(v).strip()) <= 2100])\n",
    "            if years_found >= 5:\n",
    "                header_idx = i\n",
    "                break\n",
    "        if header_idx is None:\n",
    "            header_idx = 0\n",
    "        df2 = pd.read_excel(mye_xlsx, sheet_name=name, header=header_idx)\n",
    "        # Find UK row\n",
    "        uk_row = None\n",
    "        for col in df2.columns:\n",
    "            if isinstance(col, str) and re.search(r'united\\s*kingdom|uk$', col, flags=re.I):\n",
    "                uk_row = df2[df2[col].astype(str).str.contains('United Kingdom', case=False, na=False)]\n",
    "                if not uk_row.empty:\n",
    "                    break\n",
    "        if uk_row is None or uk_row.empty:\n",
    "            # try first column as territory name\n",
    "            uk_row = df2[df2.iloc[:,0].astype(str).str.contains('United Kingdom', case=False, na=False)]\n",
    "            if uk_row.empty:\n",
    "                continue\n",
    "\n",
    "        # Collect year columns 2022 and 2023 if present\n",
    "        for y in (2022, 2023):\n",
    "            if y in df2.columns:\n",
    "                val = pd.to_numeric(uk_row.iloc[0][y], errors='coerce')\n",
    "                if pd.notna(val):\n",
    "                    out[y] = float(val) / 1000.0 if val > 1e7 else float(val)  # if persons, convert to thousands\n",
    "        if all(y in out for y in (2022, 2023)):\n",
    "            break\n",
    "\n",
    "    if not out:\n",
    "        print(\"Could not locate UK totals for 2022/2023 in MYE workbook; splice skipped.\")\n",
    "    else:\n",
    "        print(f\"MYE UK anchors found (thousands): {out}\")\n",
    "    return out\n",
    "\n",
    "# Attempt splice if necessary (EBAQ often stops at 2021Q4)\n",
    "last_q_available = ebaq_q['quarter'].iloc[-1]\n",
    "anchors = {}\n",
    "if mye_file.exists() and qrank(last_q_available) < qrank('2022Q2'):\n",
    "    anchors = read_mye_uk_totals(mye_file)\n",
    "\n",
    "def splice_with_mye(ebaq_df: pd.DataFrame, anchors_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splice quarters from last available to 2023Q4 using MYE Q2 anchors.\n",
    "    Piecewise linear interpolation between:\n",
    "      last_q -> 2022Q2 -> 2023Q2, then linear within H2 2023 to 2023Q4.\n",
    "    \"\"\"\n",
    "    if not anchors_dict:\n",
    "        return ebaq_df\n",
    "\n",
    "    df = ebaq_df.copy()\n",
    "    last_q = df['quarter'].iloc[-1]\n",
    "    last_val = df['pop_thous'].iloc[-1]\n",
    "\n",
    "    # Build anchor points (quarter -> value_thous)\n",
    "    points = { last_q: last_val }\n",
    "    if 2022 in anchors_dict:\n",
    "        points['2022Q2'] = anchors_dict[2022]\n",
    "    if 2023 in anchors_dict:\n",
    "        points['2023Q2'] = anchors_dict[2023]\n",
    "\n",
    "    # Generate required target quarters up to 2023Q4\n",
    "    target_end = '2023Q4' if '2023Q2' in points else '2022Q4'\n",
    "    new_quarters = [q for q in q_range(last_q, target_end) if q not in df['quarter'].tolist()]\n",
    "    if not new_quarters:\n",
    "        return df\n",
    "\n",
    "    # Helper: linear interpolate across quarter ranks\n",
    "    def lin_interp(q1, v1, q2, v2, qk):\n",
    "        r1, r2, rk = qrank(q1), qrank(q2), qrank(qk)\n",
    "        if r2 == r1:\n",
    "            return v1\n",
    "        frac = (rk - r1) / (r2 - r1)\n",
    "        return v1 + frac * (v2 - v1)\n",
    "\n",
    "    # Build segments:\n",
    "    segments = []\n",
    "    # last_q -> 2022Q2\n",
    "    if '2022Q2' in points and qrank('2022Q2') > qrank(last_q):\n",
    "        segments.append((last_q, points[last_q], '2022Q2', points['2022Q2']))\n",
    "    # 2022Q2 -> 2023Q2\n",
    "    if '2023Q2' in points and qrank('2023Q2') > qrank('2022Q2'):\n",
    "        segments.append(('2022Q2', points['2022Q2'], '2023Q2', points['2023Q2']))\n",
    "    # 2023Q2 -> 2023Q4 (simple linear within H2 2023)\n",
    "    if '2023Q2' in points:\n",
    "        segments.append(('2023Q2', points['2023Q2'], '2023Q4', points['2023Q2'] * (1 + 0.003)))  # small drift (0.3%) over H2\n",
    "\n",
    "    # Compute values for each missing quarter from segments\n",
    "    est = {}\n",
    "    for q1, v1, q2, v2 in segments:\n",
    "        for qk_ in q_range(q1, q2):\n",
    "            if qk_ in (q1,) or qk_ in df['quarter'].tolist():\n",
    "                continue\n",
    "            est[qk_] = lin_interp(q1, v1, q2, v2, qk_)\n",
    "\n",
    "    if not est:\n",
    "        return df\n",
    "\n",
    "    add = pd.DataFrame({\n",
    "        'quarter': list(est.keys()),\n",
    "        'pop_thous': list(est.values()),\n",
    "        'source': 'EBAQ+MYE splice'\n",
    "    })\n",
    "    add['quarter_end'] = add['quarter'].apply(q_end_date)\n",
    "    df2 = (pd.concat([df, add], ignore_index=True)\n",
    "             .sort_values('quarter')\n",
    "             .reset_index(drop=True))\n",
    "    return df2\n",
    "\n",
    "if anchors:\n",
    "    ebaq_q = splice_with_mye(ebaq_q, anchors)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) DERIVED FIELDS & QA\n",
    "# ------------------------------------------------------------\n",
    "# Persons, logs, YoY\n",
    "ebaq_q['pop_persons'] = ebaq_q['pop_thous'] * 1000.0\n",
    "ebaq_q['ln_pop']      = np.log(ebaq_q['pop_persons'])\n",
    "ebaq_q = ebaq_q.sort_values('quarter').reset_index(drop=True)\n",
    "ebaq_q['pop_yoy_pct'] = 100 * (ebaq_q['ln_pop'] - ebaq_q['ln_pop'].shift(4))\n",
    "\n",
    "# Integrity: monotonicity (allow tiny dips due to revisions; just flag)\n",
    "delta = ebaq_q['pop_persons'].diff()\n",
    "if (delta < -1000).any():  # drop more than ~1k persons QoQ as a red flag\n",
    "    print(\"WARNING: Detected quarter-on-quarter population decreases larger than ~1k persons. Inspect around:\")\n",
    "    display(ebaq_q.loc[delta < -1000, ['quarter','pop_persons']])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) FINALIZE & SAVE (to data/interim)\n",
    "# ------------------------------------------------------------\n",
    "# Select and trim columns\n",
    "pop_out = ebaq_q[['quarter','quarter_end','pop_thous','pop_persons','ln_pop','pop_yoy_pct','source']].copy()\n",
    "\n",
    "# Trim to configured analysis window\n",
    "mask2 = (pop_out['quarter'].apply(qrank) >= qrank(ANALYSIS_START_Q)) & \\\n",
    "        (pop_out['quarter'].apply(qrank) <= qrank(ANALYSIS_END_Q))\n",
    "pop_out = pop_out.loc[mask2].reset_index(drop=True)\n",
    "\n",
    "# Save\n",
    "f_pop = DATA_INTERIM / 'pop_q.csv'\n",
    "pop_out.to_csv(f_pop, index=False)\n",
    "print(f\"Saved population (quarterly) to: {f_pop}\")\n",
    "\n",
    "# Preview\n",
    "display(pop_out.head(8))\n",
    "display(pop_out.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d793a-32c8-43cb-94aa-65ede5db0241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85bb39a-29b7-4f25-953f-8d364f7869e9",
   "metadata": {},
   "source": [
    "## one standardized master panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd569794-3f10-4e2b-b4b3-6cfedf39d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote master panel -> C:\\Users\\Aniruddha\\Desktop\\Business Project_BEMM466\\Project Code\\data\\processed\\master_panel.csv (776 rows across 8 measures)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJ_ROOT = Path.cwd().resolve()\n",
    "DATA_INTERIM = PROJ_ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED = PROJ_ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "frames = []\n",
    "\n",
    "# --- Map each interim file -> standard (measure, period, value) on QUARTER keys ---\n",
    "# 1) Defence totals (quarterly nominal, long)\n",
    "f = DATA_INTERIM / \"defence_q_nominal_long.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"nominal_q_mn\":\"value\",\"component\":\"measure\"})\n",
    "    # keep only total/current/capital as separate measures\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# 2) Nominal GDP (YBHA)\n",
    "f = DATA_INTERIM / \"ybha_q.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"gdp_nom_mn\":\"value\"})\n",
    "    df[\"measure\"] = \"gdp_nominal_mn\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# 3) Real GDP level (ABMI)\n",
    "f = DATA_INTERIM / \"abmi_q.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"gdp_real_mn\":\"value\"})\n",
    "    df[\"measure\"] = \"gdp_real_mn\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# 4) GDP implied deflator (YBGB) – as-published index (base per ONS)\n",
    "f = DATA_INTERIM / \"ybgb_q.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"deflator_index\":\"value\"})\n",
    "    df[\"measure\"] = \"gdp_deflator_index\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# (Optional) FY-anchored deflator variant; keep as a separate measure\n",
    "f = DATA_INTERIM / \"ybgb_q_fyanchored.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"deflator_index_fyanchored\":\"value\"})\n",
    "    df[\"measure\"] = \"gdp_deflator_index_fyanchored\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# 5) CPIH (quarterly average index)\n",
    "f = DATA_INTERIM / \"cpih_quarterly.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"cpih_idx_q\":\"value\"})\n",
    "    df[\"measure\"] = \"cpih_index_qavg\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# 6) Population (EBAQ)\n",
    "f = DATA_INTERIM / \"pop_q.csv\"\n",
    "if f.exists():\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.rename(columns={\"quarter\":\"period\",\"pop_thous\":\"value\"})\n",
    "    df[\"measure\"] = \"population_thousands\"\n",
    "    frames.append(df[[\"measure\",\"period\",\"value\"]])\n",
    "\n",
    "# Combine & tidy\n",
    "if frames:\n",
    "    master = pd.concat(frames, ignore_index=True)\n",
    "    master[\"period\"] = master[\"period\"].astype(str)\n",
    "    master = master.dropna(subset=[\"period\",\"value\"]).sort_values([\"measure\",\"period\"]).reset_index(drop=True)\n",
    "    out_path = DATA_PROCESSED / \"master_panel.csv\"\n",
    "    master.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote master panel -> {out_path} ({len(master):,} rows across {master['measure'].nunique()} measures)\")\n",
    "else:\n",
    "    print(\"No interim files found. Make sure the six source scripts have written their outputs to /data/interim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785eabd-336b-4046-b156-9f12ab72786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2536a85-02c6-4551-b6cd-466b2b06413a",
   "metadata": {},
   "source": [
    "## Augmented Master Panel (real series via YBGB, per‑capita, and QoQ/YoY growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca97909-dab5-4bcb-bdf3-1cc16c5fac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched columns (None means not found):\n",
      "  • GDP real:      None\n",
      "  • GDP nominal:   None\n",
      "  • GDP deflator:  None\n",
      "  • Population:    None\n",
      "  • MoD total CP:  None\n",
      "  • MoD capex CP:  None\n",
      "  • MoD current CP:None\n",
      "  ! Deflator missing → cannot deflate nominal series.\n",
      "  ! Could not obtain real GDP (need either an existing real series OR nominal+deflator).\n",
      "  ! Missing nominal series for mod_total_real → skipped.\n",
      "  ! Missing nominal series for mod_cap_real → skipped.\n",
      "  ! Missing nominal series for mod_cur_real → skipped.\n",
      "  ! Population missing → skipped all per‑capita calculations.\n",
      "  ! Skipped GDP growth (no real GDP).\n",
      "\n",
      "Saved:\n",
      "  - data\\processed\\master_panel_20250902.parquet\n",
      "  - data\\processed\\master_panel_20250902.csv\n"
     ]
    }
   ],
   "source": [
    "# Robust, error-tolerant augmentation script\n",
    "# - Builds real MoD series using the GDP implied deflator (YBGB)\n",
    "# - Derives real GDP if missing (from YBHA & YBGB)\n",
    "# - Adds per‑capita versions\n",
    "# - Adds QoQ and YoY growth rates for GDP and defence (total, capex, current)\n",
    "# - Never hard-fails on missing columns: it computes whatever is feasible and prints a clear summary.\n",
    "#\n",
    "# Expected to run in your project root with a master panel already created.\n",
    "# If `df` is defined in memory, it will use that. Otherwise it will try to load from data/processed/*.\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------- Configuration -----------------------------\n",
    "\n",
    "DATA_PROCESSED = Path(\"data/processed\")\n",
    "today = pd.Timestamp.today().date()\n",
    "OUT_PARQUET = DATA_PROCESSED / f\"master_panel_{today:%Y%m%d}.parquet\"\n",
    "OUT_CSV     = DATA_PROCESSED / f\"master_panel_{today:%Y%m%d}.csv\"\n",
    "\n",
    "POSSIBLE_MASTERS = [\n",
    "    DATA_PROCESSED / \"master_panel.parquet\",\n",
    "    DATA_PROCESSED / \"master_panel_latest.parquet\",\n",
    "    DATA_PROCESSED / \"master_panel.csv\",\n",
    "]\n",
    "\n",
    "# Candidate names (very liberal). Matching is case-insensitive and punctuation-agnostic.\n",
    "CANDIDATES = {\n",
    "    \"period\": [\n",
    "        \"quarter\",\"period\",\"date\",\"obs_date\",\"time\",\"quarter_str\",\"quarterly\",\n",
    "        \"qtr\",\"year_quarter\",\"yearq\",\"date_q\",\"period_q\",\"period_quarter\"\n",
    "    ],\n",
    "    \"gdp_real\": [\n",
    "        \"gdp_real_abmi\",\"abmi\",\"gdp_cvm_abmi\",\"gdp_cvm\",\"gdp_chain_volume\",\"gdp_volume\",\n",
    "        \"gdp_real\",\"real_gdp\",\"gdpr\",\"rgdp\",\"gdp_cvm_level\",\"gdp_cvm_gbp\",\"abmi_cvm\"\n",
    "    ],\n",
    "    \"gdp_nominal\": [\n",
    "        \"gdp_nominal_ybha\",\"ybha\",\"gdp_current_prices\",\"gdp_nominal\",\"gdp_cp\",\n",
    "        \"ngdp\",\"gdp_value\",\"gdp_curr\",\"gdp_current\"\n",
    "    ],\n",
    "    \"deflator\": [\n",
    "        \"gdp_deflator_ybgb\",\"ybgb\",\"gdp_deflator\",\"gdp_deflator_index\",\n",
    "        \"gdp_implied_deflator\",\"implied_deflator_ybgb\",\"ybgb_q\",\"gdp_deflator_index_2019_100\"\n",
    "    ],\n",
    "    \"population\": [\n",
    "        \"population_q\",\"population\",\"uk_population_q\",\"pop_q\",\"pop\",\"uk_pop\",\n",
    "        \"population_thousands\",\"population_millions\",\"resident_population_q\",\"population_estimate_q\"\n",
    "    ],\n",
    "    \"mod_total_nom\": [\n",
    "        \"mod_total_nom\",\"mod_total_nominal\",\"mod_total_current_prices\",\"mod_total\",\"defence_total_nom\",\n",
    "        \"defence_total_current_prices\",\"defence_total_cp\",\"mod_total_cp\",\"def_exp_total_cp\",\"defence_total\"\n",
    "    ],\n",
    "    \"mod_cap_nom\": [\n",
    "        \"mod_cap_nom\",\"mod_capital_nominal\",\"mod_capital\",\"mod_capex_nom\",\"defence_capital_nom\",\n",
    "        \"mod_equipment_nom\",\"mod_equipment_cp\",\"defence_capex_cp\",\"equipment_expenditure_cp\"\n",
    "    ],\n",
    "    \"mod_cur_nom\": [\n",
    "        \"mod_cur_nom\",\"mod_current_nominal\",\"mod_current\",\"mod_recurrent_nom\",\"defence_current_nom\",\n",
    "        \"mod_resource_nom\",\"mod_resource_cp\",\"defence_current_cp\",\"mod_current_cp\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# ------------------------------- Helpers ---------------------------------\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    \"\"\"Normalize a column name: lowercase + alnum only.\"\"\"\n",
    "    return \"\".join(ch for ch in s.lower() if ch.isalnum())\n",
    "\n",
    "def _build_norm_map(df: pd.DataFrame) -> dict[str, str]:\n",
    "    \"\"\"Map normalized names -> original df column names (first occurrence wins).\"\"\"\n",
    "    m = {}\n",
    "    for c in df.columns:\n",
    "        nc = _norm(c)\n",
    "        if nc and nc not in m:\n",
    "            m[nc] = c\n",
    "    return m\n",
    "\n",
    "def _find_col(df: pd.DataFrame, names: list[str]) -> str | None:\n",
    "    \"\"\"Return the first matching column by normalized name; None if not found.\"\"\"\n",
    "    nm = _build_norm_map(df)\n",
    "    for cand in names:\n",
    "        nc = _norm(cand)\n",
    "        if nc in nm:\n",
    "            return nm[nc]\n",
    "    return None\n",
    "\n",
    "def _coerce_numeric(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "def _ensure_period_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure a quarterly PeriodIndex named 'quarter'.\"\"\"\n",
    "    if isinstance(df.index, pd.PeriodIndex) and df.index.freqstr and df.index.freqstr.upper().startswith(\"Q\"):\n",
    "        df.index.name = \"quarter\"\n",
    "        return df.sort_index()\n",
    "\n",
    "    # try to find a period-ish column\n",
    "    pcol = _find_col(df, CANDIDATES[\"period\"])\n",
    "    if pcol is None:\n",
    "        # As a last resort, try any column that looks like 'YYYY-Qn' strings or datetimes\n",
    "        for c in df.columns:\n",
    "            ser = df[c].astype(str)\n",
    "            if ser.str.contains(r\"^\\d{4}Q[1-4]$\", regex=True, na=False).any():\n",
    "                pcol = c\n",
    "                break\n",
    "        if pcol is None:\n",
    "            raise ValueError(\"No quarterly period column found. Please add one (e.g., 'quarter' like '2016Q3').\")\n",
    "\n",
    "    x = pd.to_datetime(df[pcol], errors=\"coerce\")\n",
    "    if x.notna().any():\n",
    "        qidx = x.dt.to_period(\"Q\")\n",
    "    else:\n",
    "        # likely 'YYYYQn' strings\n",
    "        qidx = pd.PeriodIndex(df[pcol].astype(str), freq=\"Q\")\n",
    "    out = df.set_index(qidx).sort_index()\n",
    "    out.index.name = \"quarter\"\n",
    "    return out\n",
    "\n",
    "def _deflator_factor(deflator: pd.Series) -> pd.Series:\n",
    "    \"\"\"Return multiplicative price factor from an index or factor.\"\"\"\n",
    "    d = _coerce_numeric(deflator).copy()\n",
    "    med = d.median(skipna=True)\n",
    "    if pd.isna(med):\n",
    "        raise ValueError(\"Deflator series has no numeric values.\")\n",
    "    return (d / 100.0) if med > 10 else d\n",
    "\n",
    "def _detect_population_scale(pop: pd.Series) -> int:\n",
    "    \"\"\"If median < 1e6 assume thousands → ×1000, else assume persons.\"\"\"\n",
    "    med = pop.median(skipna=True)\n",
    "    if pd.isna(med):\n",
    "        return 1\n",
    "    return 1000 if med < 1_000_000 else 1\n",
    "\n",
    "def _pct_change(s: pd.Series, periods: int) -> pd.Series:\n",
    "    out = s.div(s.shift(periods)).sub(1)\n",
    "    return out.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def _safe_add(df: pd.DataFrame, col: str, series: pd.Series) -> None:\n",
    "    \"\"\"Add/overwrite a column aligning on index.\"\"\"\n",
    "    df[col] = series.reindex(df.index)\n",
    "\n",
    "# ------------------------------- Load ------------------------------------\n",
    "\n",
    "try:\n",
    "    df  # noqa: F821\n",
    "except NameError:\n",
    "    df = None\n",
    "\n",
    "if df is None:\n",
    "    for p in POSSIBLE_MASTERS:\n",
    "        if p.exists():\n",
    "            df = pd.read_parquet(p) if p.suffix == \".parquet\" else pd.read_csv(p)\n",
    "            print(f\"Loaded master from: {p}\")\n",
    "            break\n",
    "    if df is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"Master panel not found. Ensure a DataFrame `df` exists, or place one at data/processed/master_panel.*\"\n",
    "        )\n",
    "\n",
    "# ------------------------------ Augment ----------------------------------\n",
    "\n",
    "df = _ensure_period_index(df)\n",
    "messages = []\n",
    "\n",
    "# Locate columns (case/format tolerant)\n",
    "gdp_real_col = _find_col(df, CANDIDATES[\"gdp_real\"])\n",
    "gdp_nom_col  = _find_col(df, CANDIDATES[\"gdp_nominal\"])\n",
    "defl_col     = _find_col(df, CANDIDATES[\"deflator\"])\n",
    "pop_col      = _find_col(df, CANDIDATES[\"population\"])\n",
    "mod_tot_col  = _find_col(df, CANDIDATES[\"mod_total_nom\"])\n",
    "mod_cap_col  = _find_col(df, CANDIDATES[\"mod_cap_nom\"])\n",
    "mod_cur_col  = _find_col(df, CANDIDATES[\"mod_cur_nom\"])\n",
    "\n",
    "messages.append(\"Matched columns (None means not found):\")\n",
    "messages.append(f\"  • GDP real:      {gdp_real_col}\")\n",
    "messages.append(f\"  • GDP nominal:   {gdp_nom_col}\")\n",
    "messages.append(f\"  • GDP deflator:  {defl_col}\")\n",
    "messages.append(f\"  • Population:    {pop_col}\")\n",
    "messages.append(f\"  • MoD total CP:  {mod_tot_col}\")\n",
    "messages.append(f\"  • MoD capex CP:  {mod_cap_col}\")\n",
    "messages.append(f\"  • MoD current CP:{mod_cur_col}\")\n",
    "\n",
    "# Prepare deflator factor if available\n",
    "price_factor = None\n",
    "if defl_col is not None:\n",
    "    deflator_ser = _coerce_numeric(df[defl_col]).ffill().bfill()\n",
    "    price_factor = _deflator_factor(deflator_ser)\n",
    "else:\n",
    "    messages.append(\"  ! Deflator missing → cannot deflate nominal series.\")\n",
    "\n",
    "# -------- GDP real (prefer existing; else derive from nominal & deflator) --------\n",
    "gdp_real_name = None\n",
    "if gdp_real_col is not None:\n",
    "    gdp_real = _coerce_numeric(df[gdp_real_col])\n",
    "    gdp_real_name = gdp_real_col  # keep original name\n",
    "else:\n",
    "    if (gdp_nom_col is not None) and (price_factor is not None):\n",
    "        gdp_nom = _coerce_numeric(df[gdp_nom_col])\n",
    "        gdp_real = gdp_nom / price_factor\n",
    "        gdp_real_name = \"gdp_real_abmi\"  # standardize output name\n",
    "        _safe_add(df, gdp_real_name, gdp_real)\n",
    "        messages.append(f\"  • Derived real GDP as `{gdp_real_name}` from {gdp_nom_col}/{defl_col}.\")\n",
    "    else:\n",
    "        gdp_real = None\n",
    "        messages.append(\"  ! Could not obtain real GDP (need either an existing real series OR nominal+deflator).\")\n",
    "\n",
    "# -------- Deflate MoD nominal series to real (2019=100 style if YBGB) --------\n",
    "def add_mod_real(nom_col: str, out_name: str):\n",
    "    if nom_col is None:\n",
    "        messages.append(f\"  ! Missing nominal series for {out_name} → skipped.\")\n",
    "        return\n",
    "    if price_factor is None:\n",
    "        messages.append(f\"  ! Missing deflator for {out_name} → skipped.\")\n",
    "        return\n",
    "    nom = _coerce_numeric(df[nom_col])\n",
    "    _safe_add(df, out_name, nom / price_factor)\n",
    "    messages.append(f\"  • Created {out_name} from {nom_col}/{defl_col}.\")\n",
    "\n",
    "add_mod_real(mod_tot_col, \"mod_total_real\")\n",
    "add_mod_real(mod_cap_col, \"mod_cap_real\")\n",
    "add_mod_real(mod_cur_col, \"mod_cur_real\")\n",
    "\n",
    "# -------- Per‑capita versions (if population available) --------\n",
    "if pop_col is not None:\n",
    "    pop = _coerce_numeric(df[pop_col]).ffill().bfill()\n",
    "    pop_scale = _detect_population_scale(pop)\n",
    "    persons = pop * pop_scale\n",
    "\n",
    "    # GDP per-capita (if we have real GDP)\n",
    "    if gdp_real_name is not None:\n",
    "        _safe_add(df, \"gdp_real_pc\", df[gdp_real_name] / persons)\n",
    "        messages.append(\"  • Added gdp_real_pc.\")\n",
    "    else:\n",
    "        messages.append(\"  ! Skipped gdp_real_pc (no real GDP).\")\n",
    "\n",
    "    # MoD per-capita (if real series exist)\n",
    "    for base in [\"mod_total_real\", \"mod_cap_real\", \"mod_cur_real\"]:\n",
    "        if base in df.columns:\n",
    "            _safe_add(df, f\"{base}_pc\", df[base] / persons)\n",
    "            messages.append(f\"  • Added {base}_pc.\")\n",
    "else:\n",
    "    messages.append(\"  ! Population missing → skipped all per‑capita calculations.\")\n",
    "\n",
    "# -------- Growth rates (QoQ & YoY) for GDP (real) and MoD real series --------\n",
    "def add_growth(series_name: str, label: str | None = None):\n",
    "    if series_name not in df.columns:\n",
    "        messages.append(f\"  ! Growth skipped (missing series): {series_name}\")\n",
    "        return\n",
    "    base = label or series_name\n",
    "    s = _coerce_numeric(df[series_name])\n",
    "    df[f\"{base}_qoq_pct\"] = _pct_change(s, 1)\n",
    "    df[f\"{base}_yoy_pct\"] = _pct_change(s, 4)\n",
    "    messages.append(f\"  • Added QoQ/YoY growth for {base}.\")\n",
    "\n",
    "# GDP growth (use the detected/derived real GDP)\n",
    "if gdp_real_name is not None:\n",
    "    add_growth(gdp_real_name)  # columns: <name>_qoq_pct, <name>_yoy_pct\n",
    "else:\n",
    "    messages.append(\"  ! Skipped GDP growth (no real GDP).\")\n",
    "\n",
    "# Defence growth (real)\n",
    "for base in [\"mod_total_real\", \"mod_cap_real\", \"mod_cur_real\"]:\n",
    "    if base in df.columns:\n",
    "        add_growth(base)\n",
    "\n",
    "# ------------------------------- Save -----------------------------------\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(OUT_PARQUET)\n",
    "df.to_csv(OUT_CSV, index=True)\n",
    "\n",
    "print(\"\\n\".join(messages))\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"  - {OUT_PARQUET}\")\n",
    "print(f\"  - {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719aaece-1b8e-4640-962c-8888ff98a1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
